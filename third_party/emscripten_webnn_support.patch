diff --git a/emcc.py b/emcc.py
index a6ec69517..aa8b2e64f 100755
--- a/emcc.py
+++ b/emcc.py
@@ -2424,6 +2424,7 @@ def phase_linker_setup(options, state, newargs, settings_map):
   if settings.RELOCATABLE or \
      settings.BUILD_AS_WORKER or \
      settings.USE_WEBGPU or \
+     settings.USE_WEBNN or \
      settings.USE_PTHREADS or \
      settings.OFFSCREENCANVAS_SUPPORT or \
      settings.LEGACY_GL_EMULATION or \
@@ -3200,9 +3201,6 @@ def parse_args(newargs):
       else:
         config.generate_config(optarg)
       should_exit = True
-    # Record USE_PTHREADS setting because it controls whether --shared-memory is passed to lld
-    elif arg == '-pthread':
-      settings_changes.append('USE_PTHREADS=1')
     elif arg in ('-fno-diagnostics-color', '-fdiagnostics-color=never'):
       colored_logger.disable()
       diagnostics.color_enabled = False
diff --git a/src/closure-externs/closure-externs.js b/src/closure-externs/closure-externs.js
index 28fd2968b..2334f7a9a 100644
--- a/src/closure-externs/closure-externs.js
+++ b/src/closure-externs/closure-externs.js
@@ -199,6 +199,11 @@ var currentFrame;
 var currentTime;
 var sampleRate;
 
+/*
+ * WebNN globals
+ */
+var MLGraphBuilder;
+
 /*
  * WebGPU globals
  */
diff --git a/src/library_html5_webnn.js b/src/library_html5_webnn.js
new file mode 100644
index 000000000..432ebaca1
--- /dev/null
+++ b/src/library_html5_webnn.js
@@ -0,0 +1,31 @@
+mergeInto(LibraryManager.library, {
+  emscripten_webnn_create_context__deps: ['$WebNN'],
+  emscripten_webnn_create_context__postset: 'WebNN.initManagers();',
+  emscripten_webnn_create_context: function(optionsPtr) {
+    var options = {
+      'devicePreference': 'default',
+      'powerPreference': 'default'
+    };
+
+    var DevicePreference = [
+      'default',
+      'gpu',
+      'cpu',
+    ];
+    var PowerPreference = [
+      'default',
+      'high-performance',
+      'low-power',
+    ];
+    if (optionsPtr !== 0) {
+      options = {
+          'devicePreference': DevicePreference[
+            {{{ makeGetValue('optionsPtr', C_STRUCTS.WNNContextOptions.devicePreference, 'i32', false, true) }}}],
+          'powerPreference': PowerPreference[
+            {{{ makeGetValue('optionsPtr', C_STRUCTS.WNNContextOptions.powerPreference, 'i32', false, true) }}}]
+      };
+    }
+    var context = navigator['ml'].createContext(options);
+    return WebNN.mgrContext.create(context);
+  },
+});
diff --git a/src/library_pthread.js b/src/library_pthread.js
index 0f5cc4260..cd311d8e3 100644
--- a/src/library_pthread.js
+++ b/src/library_pthread.js
@@ -295,7 +295,7 @@ var LibraryPThread = {
       };
 
 #if ENVIRONMENT_MAY_BE_NODE
-      if (ENVIRONMENT_IS_NODE) {
+      if (ENVIRONMENT_IS_NODE && worker.on !== undefined) {
         worker.on('message', function(data) {
           worker.onmessage({ data: data });
         });
diff --git a/src/library_webnn.js b/src/library_webnn.js
new file mode 100644
index 000000000..f6831b962
--- /dev/null
+++ b/src/library_webnn.js
@@ -0,0 +1,907 @@
+/**
+ * @license
+ * Copyright 2021 The Emscripten Authors
+ * SPDX-License-Identifier: MIT
+ */
+
+/*
+ * WebNN support.
+ *
+ * This file implements the common C header <webnn/webnn.h> on top of the
+ * browser's native JS WebNN implementation. This allows applications targeting
+ * webnn-native (https://github.com/webmachinelearning/webnn-native) also target the Web with the
+ * same API and fairly minimal changes - similar to OpenGL ES 2.0/3.0
+ * on WebGL 1.0/2.0.
+ */
+
+{{{ (function() {
+  // Helper functions for code generation
+  global.webnn = {
+    makeInitManager: function(type) {
+      var mgr = 'WebNN.mgr' + type
+      return mgr + ' = ' + mgr + ' || makeManager();';
+    },
+
+    makeReferenceRelease: function(type) {
+      var s = '';
+      s += 'wnn' + type + 'Reference: function(id) {\n';
+      s += '  WebNN.mgr' + type + '.reference(id);\n'
+      s += '},\n';
+      s += 'wnn' + type + 'Release: function(id) {\n';
+      s += '  WebNN.mgr' + type + '.release(id);\n'
+      s += '},';
+      return s;
+    },
+
+    makeU64ToNumber: function(lowName, highName) {
+      var ret = '('
+      if (ASSERTIONS) {
+        ret += 'assert(' + highName + ' < 0x200000), ';
+      }
+      ret += highName + ' * 0x100000000 + ' + lowName + ')\n'
+      return ret;
+    },
+    makeGetBool: function(struct, offset) {
+      // In an actual build, bool seems to be i8. But on the off-chance it's i32, on little-endian
+      // this will still work as long as the value of 'true' isn't zero in the lowest byte.
+      return '(' + makeGetValue(struct, offset, 'i8') + ' !== 0)';
+    },
+    makeGetU32: function(struct, offset) {
+      return makeGetValue(struct, offset, 'i32', false, true);
+    },
+    makeGetI32: function(struct, offset) {
+      return makeGetValue(struct, offset, 'i32', false, false);
+    },
+    makeGetF32: function(struct, offset) {
+      return makeGetValue(struct, offset, 'float');
+    },
+    makeGetU64: function(struct, offset) {
+      var l = makeGetValue(struct, offset, 'i32', false, true);
+      var h = makeGetValue('(' + struct + ' + 4)', offset, 'i32', false, true)
+      return h + ' * 0x100000000 + ' + l
+    },
+    makeCheck: function(str) {
+      if (!ASSERTIONS) return '';
+      return 'assert(' + str + ');';
+    },
+    makeCheckDefined: function(name) {
+      return this.makeCheck('typeof ' + name + ' !== "undefined"');
+    },
+  };
+  return null;
+})(); }}}
+
+var LibraryWebNN = {
+  $WebNN: {
+    initManagers: function() {
+      if (WebNN.mgrContext) return;
+
+      function makeManager() {
+        return {
+          objects: {},
+          nextId: 1,
+          create: function(object, wrapper /* = {} */) {
+            wrapper = wrapper || {};
+
+            var id = this.nextId++;
+            {{{ webnn.makeCheck("typeof this.objects[id] === 'undefined'") }}}
+            wrapper.refcount = 1;
+            wrapper.object = object;
+            this.objects[id] = wrapper;
+            return id;
+          },
+          get: function(id) {
+            if (id === 0) return undefined;
+            var o = this.objects[id];
+            {{{ webnn.makeCheckDefined('o') }}}
+            return o.object;
+          },
+          reference: function(id) {
+            var o = this.objects[id];
+            {{{ webnn.makeCheckDefined('o') }}}
+            o.refcount++;
+          },
+          release: function(id) {
+            var o = this.objects[id];
+            {{{ webnn.makeCheckDefined('o') }}}
+            {{{ webnn.makeCheck('o.refcount > 0') }}}
+            o.refcount--;
+            if (o.refcount <= 0) {
+              delete this.objects[id];
+            }
+          },
+        };
+      }
+
+      {{{ webnn.makeInitManager('Context') }}}
+      {{{ webnn.makeInitManager('FusionOperator') }}}
+      {{{ webnn.makeInitManager('Graph') }}}
+      {{{ webnn.makeInitManager('GraphBuilder') }}}
+      {{{ webnn.makeInitManager('Instance') }}}
+      {{{ webnn.makeInitManager('NamedInputs') }}}
+      {{{ webnn.makeInitManager('NamedOutputs') }}}
+      {{{ webnn.makeInitManager('NamedOperands') }}}
+      {{{ webnn.makeInitManager('Operand') }}}
+      {{{ webnn.makeInitManager('OperandArray') }}}
+      {{{ webnn.makeInitManager('OperatorArray') }}}
+    },
+
+    AutoPad: [
+      'explicit',
+      'same-upper',
+      'same-lower',
+    ],
+    ComputeGraphStatus: [
+      'success',
+      'error',
+      'context-lost',
+      'unknown',
+    ],
+    ConvTranspose2dFilterOperandLayout: [
+      "iohw",
+      "hwoi",
+      "ohwi",
+    ],
+    Conv2dFilterOperandLayout: [
+      "oihw",
+      "hwio",
+      "ohwi",
+      "ihwo",
+    ],
+    DevicePreference: [
+      'default',
+      'gpu',
+      'cpu',
+    ],
+    ErrorFilter: [
+      'none',
+      'validation',
+      'out-of-memory',
+    ],
+    ErrorType: [
+      'no-error',
+      'validation',
+      'out-of-memory',
+      'unknown',
+      'device-lost',
+    ],
+    InputOperandLayout: [
+      'nchw',
+      'nhwc',
+    ],
+    InterpolationMode: [
+      'nearest-neighbor',
+      'linear',
+    ],
+    OperandType: [
+      'float32',
+      'float16',
+      'int32',
+      'uint32',
+      'int8',
+      'uint8',
+    ],
+    PaddingMode: [
+      'constant',
+      'edge',
+      'reflection',
+      'symmetric',
+    ],
+    PowerPreference: [
+      'default',
+      'high_performance',
+      'low_power',
+    ],
+    RecurrentNetworkDirection: [
+      'forward',
+      'backward',
+      'both',
+    ],
+    RecurrentNetworkWeightLayout: [
+      'zrn',
+      'rzn',
+    ],
+    RoundingType: [
+      'floor',
+      'ceil',
+    ],
+
+    makeI32Array: function(count, arrayPtr) {
+      if (count === 0 || arrayPtr === 0) {
+        return undefined;
+      }
+      var array = [];
+      for (var i = 0; i < count; ++i, arrayPtr += 4) {
+        array.push({{{ webnn.makeGetI32('arrayPtr', 0) }}});
+      }
+      return array;
+    },
+
+    makeU32Array: function(count, arrayPtr) {
+      if (count === 0 || arrayPtr === 0) {
+        return undefined;
+      }
+      var array = [];
+      for (var i = 0; i < count; ++i, arrayPtr += 4) {
+        array.push({{{ webnn.makeGetU32('arrayPtr', 0) }}});
+      }
+      return array;
+    },
+
+    makeF32Array: function(count, arrayPtr) {
+      if (count === 0 || arrayPtr === 0) {
+        return undefined;
+      }
+      var array = [];
+      for (var i = 0; i < count; ++i, arrayPtr += 4) {
+        array.push({{{ webnn.makeGetF32('arrayPtr', 0) }}});
+      }
+      return array;
+    },
+
+    makeArrayBufferView: function(ptr, type = "float32") {
+      const offset = {{{ makeGetValue('ptr', C_STRUCTS.WNNArrayBufferView.buffer, '*') }}} +
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNArrayBufferView.byteOffset) }}};
+      const byteSize = {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNArrayBufferView.byteLength) }}};
+      if (type === "float32") {
+        return new Float32Array(HEAPU8.buffer, offset, byteSize / Float32Array.BYTES_PER_ELEMENT);
+      } else if (type === "uint32") {
+        return new Uint32Array(HEAPU8.buffer, offset, byteSize / Uint32Array.BYTES_PER_ELEMENT);
+      } else if (type === "int32") {
+        return new Int32Array(HEAPU8.buffer, offset, byteSize / Uint32Array.BYTES_PER_ELEMENT);
+      } else {
+        // TODO: support other array buffer view types.
+        console.warn(`operand type ${type} is not supported.`);
+        assert(false);
+      }
+    },
+
+    makeResource: function(ptr) {
+      return WebNN.makeArrayBufferView(ptr + {{{ C_STRUCTS.WNNResource.arrayBufferView }}});
+    },
+
+    makeClampOptions: function(ptr) {
+      return {
+        "minValue": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNClampOptions.minValue) }}},
+        "maxValue": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNClampOptions.maxValue) }}},
+      };
+    },
+
+    makeBatchNormOptions: function(ptr) {
+      return {
+        "scale": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNBatchNormOptions.scale, '*') }}}),
+        "bias": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNBatchNormOptions.bias, '*') }}}),
+        "axis": {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNBatchNormOptions.axis) }}},
+        "epsilon": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNBatchNormOptions.epsilon) }}},
+        "activation": WebNN.mgrFusionOperator.get({{{ makeGetValue('ptr', C_STRUCTS.WNNBatchNormOptions.activation, '*') }}}),
+      };
+    },
+
+    makeGemmOptions: function(ptr) {
+      return {
+        "c": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNGemmOptions.c, '*') }}}),
+        "alpha": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNGemmOptions.alpha) }}},
+        "beta": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNGemmOptions.beta) }}},
+        "aTranspose": {{{ webnn.makeGetBool('ptr', C_STRUCTS.WNNGemmOptions.aTranspose)}}},
+        "bTranspose": {{{ webnn.makeGetBool('ptr', C_STRUCTS.WNNGemmOptions.bTranspose)}}},
+      };
+    },
+
+    makeGruOptions: function(ptr) {
+      return {
+        "bias": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNGruOptions.bias, '*') }}}),
+        "recurrentBias": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNGruOptions.recurrentBias, '*') }}}),
+        "initialHiddenState": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNGruOptions.initialHiddenState, '*') }}}),
+        "resetAfter": {{{ webnn.makeGetBool('ptr', C_STRUCTS.WNNGruOptions.resetAfter)}}},
+        "returnSequence": {{{ webnn.makeGetBool('ptr', C_STRUCTS.WNNGruOptions.returnSequence)}}},
+        "direction": WebNN.RecurrentNetworkDirection[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNGruOptions.direction) }}}
+        ],
+        "layout": WebNN.RecurrentNetworkWeightLayout[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNGruOptions.layout) }}}
+        ],
+        "activations": WebNN.mgrOperatorArray.get({{{ makeGetValue('ptr', C_STRUCTS.WNNGruOptions.activations, '*') }}}),
+      };
+    },
+
+    makeLeakyReluOptions: function(ptr) {
+      return {
+        "alpha": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNLeakyReluOptions.alpha) }}},
+      };
+    },
+
+    makeOperandDescriptor: function(ptr) {
+      return {
+        "type": WebNN.OperandType[
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNOperandDescriptor.type) }}}
+        ],
+        "dimensions": WebNN.makeI32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNOperandDescriptor.dimensionsCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNOperandDescriptor.dimensions, '*') }}}
+        ),
+      };
+    },
+
+    makeConvTranspose2dOptions: function(ptr) {
+      return {
+        "padding": WebNN.AutoPad[
+            {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.autoPad) }}}
+          ] === 'explicit' ? WebNN.makeI32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.paddingCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.padding, '*') }}}
+          ) : undefined,
+        "strides": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.stridesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.strides, '*') }}}
+        ),
+        "dilations": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.dilationsCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.dilations, '*') }}}
+        ),
+        "outputPadding": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.outputPaddingCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.outputPadding, '*') }}}
+        ),
+        "outputSizes": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.outputSizesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.outputSizes, '*') }}}
+        ),
+        "autoPad": WebNN.AutoPad[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.autoPad) }}}
+        ],
+        "groups": {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.groups) }}},
+        "inputLayout": WebNN.InputOperandLayout[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.inputLayout) }}}
+        ],
+        "filterLayout": WebNN.ConvTranspose2dFilterOperandLayout[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConvTranspose2dOptions.filterLayout) }}}
+        ],
+        "bias": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.bias, '*') }}}),
+        "activation": WebNN.mgrFusionOperator.get({{{ makeGetValue('ptr', C_STRUCTS.WNNConvTranspose2dOptions.activation, '*') }}}),
+      };
+    },
+
+    makeConv2dOptions: function(ptr) {
+      return {
+        "padding": WebNN.AutoPad[
+            {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConv2dOptions.autoPad) }}}
+          ] === 'explicit' ? WebNN.makeI32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConv2dOptions.paddingCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNConv2dOptions.padding, '*') }}}
+          ) : undefined,
+        "strides": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConv2dOptions.stridesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNConv2dOptions.strides, '*') }}}
+        ),
+        "dilations": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNConv2dOptions.dilationsCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNConv2dOptions.dilations, '*') }}}
+        ),
+        "autoPad": WebNN.AutoPad[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConv2dOptions.autoPad) }}}
+        ],
+        "groups": {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConv2dOptions.groups) }}},
+        "inputLayout": WebNN.InputOperandLayout[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConv2dOptions.inputLayout) }}}
+        ],
+        "filterLayout": WebNN.Conv2dFilterOperandLayout[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNConv2dOptions.filterLayout) }}}
+        ],
+        "bias": WebNN.mgrOperand.get({{{ makeGetValue('ptr', C_STRUCTS.WNNConv2dOptions.bias, '*') }}}),
+        "activation": WebNN.mgrFusionOperator.get({{{ makeGetValue('ptr', C_STRUCTS.WNNConv2dOptions.activation, '*') }}}),
+      };
+    },
+
+    makePool2dOptions: function(ptr) {
+      return {
+        "windowDimensions": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNPool2dOptions.windowDimensionsCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNPool2dOptions.windowDimensions, '*') }}}
+        ),
+        "padding": WebNN.AutoPad[
+            {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNPool2dOptions.autoPad) }}}
+          ] === 'explicit' ? WebNN.makeI32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNPool2dOptions.paddingCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNPool2dOptions.padding, '*') }}}
+          ) : undefined,
+        "strides": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNPool2dOptions.stridesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNPool2dOptions.strides, '*') }}}
+        ),
+        "dilations": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNPool2dOptions.dilationsCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNPool2dOptions.dilations, '*') }}}
+        ),
+        "autoPad": WebNN.AutoPad[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNPool2dOptions.autoPad) }}}
+        ],
+        "layout": WebNN.InputOperandLayout[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNPool2dOptions.layout) }}}
+        ],
+        "roundingType": WebNN.RoundingType[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNPool2dOptions.roundingType) }}}
+        ],
+        "outputSizes": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNPool2dOptions.outputSizesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNPool2dOptions.outputSizes, '*') }}}
+        ),
+      };
+    },
+
+    makeSplitOptions: function(ptr) {
+      return {
+        "axis": {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNSplitOptions.axis) }}},
+      };
+    },
+
+    makeSqueezeOptions: function(ptr) {
+      return {
+        "axes": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNSqueezeOptions.axesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNSqueezeOptions.axes, '*') }}}
+        )
+      };
+    },
+
+    makePadOptions: function(ptr) {
+      return {
+        "mode": WebNN.PaddingMode[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNPadOptions.mode) }}}
+        ],
+        "value": {{{ webnn.makeGetF32('ptr', C_STRUCTS.WNNPadOptions.value) }}},
+      }
+    },
+
+    makeReduceOptions: function(ptr) {
+      return {
+        "axes": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNReduceOptions.axesCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNReduceOptions.axes, '*') }}}
+        ),
+        "keepDimensions": {{{ webnn.makeGetBool('ptr', C_STRUCTS.WNNReduceOptions.keepDimensions)}}},
+      }
+    },
+
+    makeInput: function(ptr) {
+      if ({{{ makeGetValue('ptr', C_STRUCTS.WNNInput.dimensions, '*') }}} === 0) {
+        return WebNN.makeResource(ptr + {{{ C_STRUCTS.WNNInput.resource }}});
+      } else {
+        return {
+          "resource": WebNN.makeResource(ptr + {{{ C_STRUCTS.WNNInput.resource }}}),
+          "dimensions": WebNN.makeI32Array(
+              {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNInput.dimensionsCount) }}},
+              {{{ makeGetValue('ptr', C_STRUCTS.WNNInput.dimensions, '*') }}}
+          ),
+        };
+      }
+    },
+
+    makeTransposeOptions: function(ptr) {
+      return {
+        "permutation": WebNN.makeI32Array(
+          {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNTransposeOptions.permutationCount) }}},
+          {{{ makeGetValue('ptr', C_STRUCTS.WNNTransposeOptions.permutation, '*') }}}
+        )
+      };
+    },
+
+    makeResample2dOptions: function(ptr) {
+      return {
+        "mode": WebNN.InterpolationMode[
+          {{{ webnn.makeGetI32('ptr', C_STRUCTS.WNNResample2dOptions.mode) }}}
+        ],
+        "scales": WebNN.makeF32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNResample2dOptions.scalesCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNResample2dOptions.scales, '*') }}}
+        ),
+        "sizes": WebNN.makeI32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNResample2dOptions.sizesCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNResample2dOptions.sizes, '*') }}}
+        ),
+        "axes": WebNN.makeI32Array(
+            {{{ webnn.makeGetU32('ptr', C_STRUCTS.WNNResample2dOptions.axesCount) }}},
+            {{{ makeGetValue('ptr', C_STRUCTS.WNNResample2dOptions.axes, '*') }}}
+        ),
+      };
+    },
+
+  },
+
+  // *Reference/*Release
+
+  {{{ webnn.makeReferenceRelease('Context') }}}
+  {{{ webnn.makeReferenceRelease('FusionOperator') }}}
+  {{{ webnn.makeReferenceRelease('Graph') }}}
+  {{{ webnn.makeReferenceRelease('GraphBuilder') }}}
+  {{{ webnn.makeReferenceRelease('Instance') }}}
+  {{{ webnn.makeReferenceRelease('NamedInputs') }}}
+  {{{ webnn.makeReferenceRelease('NamedOperands') }}}
+  {{{ webnn.makeReferenceRelease('NamedOutputs') }}}
+  {{{ webnn.makeReferenceRelease('Operand') }}}
+  {{{ webnn.makeReferenceRelease('OperandArray') }}}
+  {{{ webnn.makeReferenceRelease('OperatorArray') }}}
+
+  // Methods of GraphBuilder
+  wnnGraphBuilderAdd: function(builderId, aId, bId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var a = WebNN.mgrOperand.get(aId);
+    var b = WebNN.mgrOperand.get(bId);
+    var c = builder["add"](a, b);
+    return WebNN.mgrOperand.create(c);
+  },
+
+  wnnGraphBuilderAveragePool2d: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makePool2dOptions(optionsPtr);
+    var pool2d = builder["averagePool2d"](input, options);
+    return WebNN.mgrOperand.create(pool2d);
+  },
+
+  wnnGraphBuilderBatchNorm: function(builderId, inputId, meanId, varianceId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var mean = WebNN.mgrOperand.get(meanId);
+    var variance = WebNN.mgrOperand.get(varianceId);
+    var options = WebNN.makeBatchNormOptions(optionsPtr);
+    var output = builder["batchNormalization"](input, mean, variance, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderBuild: function(builderId, namedOperandsId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var namedOperands = WebNN.mgrNamedOperands.get(namedOperandsId);
+    try {
+      var graph = builder["build"](namedOperands);
+      return WebNN.mgrGraph.create(graph);
+    } catch (error) {
+      console.log('builder.build failed: ' + error);
+      return 0;  // nullptr
+    }
+  },
+
+  wnnGraphBuilderClamp: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makeClampOptions(optionsPtr);
+    var clamp = builder["clamp"](input, options);
+    return WebNN.mgrOperand.create(clamp);
+  },
+
+  wnnGraphBuilderClampOperator: function(builderId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var options = WebNN.makeClampOptions(optionsPtr);
+    var clamp = builder["clamp"](options);
+    return WebNN.mgrFusionOperator.create(clamp);
+  },
+
+  wnnGraphBuilderConcat: function(builderId, inputsCount, inputsPtr, axis) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var inputIds = WebNN.makeI32Array(inputsCount, inputsPtr);
+    var inputs = [];
+    for (var i = 0; i < inputIds.length; ++i) {
+      inputs.push(WebNN.mgrOperand.get(inputIds[i]));
+    }
+    var output = builder["concat"](inputs, axis);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderConstant: function(builderId, descPtr, arrayBufferViewPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var desc = WebNN.makeOperandDescriptor(descPtr);
+    var buffer = WebNN.makeArrayBufferView(arrayBufferViewPtr, desc.type);
+    var constant;
+    if (desc["dimensions"] === undefined) {
+      constant = builder["constant"](buffer[0]);
+    } else {
+      constant = builder["constant"](desc, buffer);
+    }
+    return WebNN.mgrOperand.create(constant);
+  },
+
+  wnnGraphBuilderConv2d: function(builderId, inputId, filterId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var filter = WebNN.mgrOperand.get(filterId);
+    var options = WebNN.makeConv2dOptions(optionsPtr);
+    var conv2d = builder["conv2d"](input, filter, options);
+    return WebNN.mgrOperand.create(conv2d);
+  },
+
+  wnnGraphBuilderConvTranspose2d: function(builderId, inputId, filterId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var filter = WebNN.mgrOperand.get(filterId);
+    var options = WebNN.makeConvTranspose2dOptions(optionsPtr);
+    var conv2d = builder["convTranspose2d"](input, filter, options);
+    return WebNN.mgrOperand.create(conv2d);
+  },
+
+  wnnGraphBuilderDiv: function(builderId, aId, bId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var a = WebNN.mgrOperand.get(aId);
+    var b = WebNN.mgrOperand.get(bId);
+    var c = builder["div"](a, b);
+    return WebNN.mgrOperand.create(c);
+  },
+
+  wnnGraphBuilderGemm: function(builderId, aId, bId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var a = WebNN.mgrOperand.get(aId);
+    var b = WebNN.mgrOperand.get(bId);
+    var options = WebNN.makeGemmOptions(optionsPtr);
+    var output = builder["gemm"](a, b, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderGru: function(builderId, inputId, weightId, recurrentWeightId,
+    steps, hiddenSize, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var weight = WebNN.mgrOperand.get(weightId);
+    var recurrentWeight = WebNN.mgrOperand.get(recurrentWeightId);
+    var options = WebNN.makeGruOptions(optionsPtr);
+    var gru = builder["gru"](input, weight, recurrentWeight, steps, hiddenSize, options);
+  return WebNN.mgrOperandArray.create(gru);
+},
+
+  wnnGraphBuilderInput: function(builderId, namePtr, descPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var name = UTF8ToString(namePtr);
+    var desc = WebNN.makeOperandDescriptor(descPtr);
+    var input = builder["input"](name, desc);
+    return WebNN.mgrOperand.create(input);
+  },
+
+  wnnGraphBuilderHardSwish: function(builderId, inputId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var output = builder["hardSwish"](input);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderHardSwishOperator: function(builderId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var output = builder["hardSwish"]();
+    return WebNN.mgrFusionOperator.create(output);
+  },
+
+  wnnGraphBuilderLeakyRelu: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makeLeakyReluOptions(optionsPtr);
+    var output = builder["leakyRelu"](input, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderLeakyReluOperator: function(builderId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var options = WebNN.makeLeakyReluOptions(optionsPtr);
+    var output = builder["leakyRelu"](options);
+    return WebNN.mgrFusionOperator.create(output);
+  },
+
+  wnnGraphBuilderMatmul: function(builderId, aId, bId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var a = WebNN.mgrOperand.get(aId);
+    var b = WebNN.mgrOperand.get(bId);
+    var c = builder["matmul"](a, b);
+    return WebNN.mgrOperand.create(c);
+  },
+
+  wnnGraphBuilderMaxPool2d: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makePool2dOptions(optionsPtr);
+    var pool2d = builder["maxPool2d"](input, options);
+    return WebNN.mgrOperand.create(pool2d);
+  },
+
+  wnnGraphBuilderMul: function(builderId, aId, bId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var a = WebNN.mgrOperand.get(aId);
+    var b = WebNN.mgrOperand.get(bId);
+    var c = builder["mul"](a, b);
+    return WebNN.mgrOperand.create(c);
+  },
+
+  wnnGraphBuilderPad: function(builderId, inputId, paddingId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var padding = WebNN.mgrOperand.get(paddingId);
+    var options = WebNN.makePadOptions(optionsPtr);
+    var output = builder["pad"](input, padding, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderReduceMean: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makeReduceOptions(optionsPtr);
+    var output = builder["reduceMean"](input, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderRelu: function(builderId, inputId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var output = builder["relu"](input);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderReluOperator: function(builderId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var output = builder["relu"]();
+    return WebNN.mgrFusionOperator.create(output);
+  },
+
+  wnnGraphBuilderResample2d: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makeResample2dOptions(optionsPtr);
+    var output = builder["resample2d"](input, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderReshape: function(builderId, inputId, newShapePtr, newShapeCount) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var newShape = WebNN.makeI32Array(newShapeCount, newShapePtr);
+    var output = builder["reshape"](input, newShape);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderSigmoid: function(builderId, inputId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var output = builder["sigmoid"](input);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderSigmoidOperator: function(builderId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var output = builder["sigmoid"]();
+    return WebNN.mgrFusionOperator.create(output);
+  },
+
+  wnnGraphBuilderSoftmax: function(builderId, inputId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var output = builder["softmax"](input);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderSplit: function(builderId, inputId, splitsPtr, splitsCount, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var splits = WebNN.makeU32Array(splitsCount, splitsPtr);
+    if (splitsCount == 1) splits = splits[0];
+    var options = WebNN.makeSplitOptions(optionsPtr);
+    var output = builder["split"](input, splits, options);
+    return WebNN.mgrOperandArray.create(output);
+  },
+
+  wnnGraphBuilderSqueeze: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makeSqueezeOptions(optionsPtr);
+    var output = builder["squeeze"](input, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderSub: function(builderId, aId, bId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var a = WebNN.mgrOperand.get(aId);
+    var b = WebNN.mgrOperand.get(bId);
+    var c = builder["sub"](a, b);
+    return WebNN.mgrOperand.create(c);
+  },
+
+  wnnGraphBuilderTanh: function(builderId, inputId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var output = builder["tanh"](input);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnGraphBuilderTanhOperator: function(builderId) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var output = builder["tanh"]();
+    return WebNN.mgrFusionOperator.create(output);
+  },
+
+  wnnGraphBuilderTranspose: function(builderId, inputId, optionsPtr) {
+    var builder = WebNN.mgrGraphBuilder.get(builderId);
+    var input = WebNN.mgrOperand.get(inputId);
+    var options = WebNN.makeTransposeOptions(optionsPtr);
+    var output = builder["transpose"](input, options);
+    return WebNN.mgrOperand.create(output);
+  },
+
+  wnnOperandArrayGet: function(operandArrayId, indexId) {
+    var operandArray = WebNN.mgrOperandArray.get(operandArrayId);
+    var operand = operandArray[indexId];
+    return WebNN.mgrOperand.create(operand);
+  },
+
+  wnnOperandArraySize: function(operandArrayId) {
+    var operandArray = WebNN.mgrOperandArray.get(operandArrayId);
+    return operandArray.length;
+  },
+
+  wnnOperatorArrayGet: function(operatorArrayId, indexId) {
+    var operatorArray = WebNN.mgrOperatorArray.get(operatorArrayId);
+    var operator = operatorArray[indexId];
+    return WebNN.mgrFusionOperator.create(operator);
+  },
+
+  wnnOperatorArraySet: function(operatorArrayId, wnnOperatorId) {
+    var operatorArray = WebNN.mgrOperatorArray.get(operatorArrayId);
+    var wnnOperator = WebNN.mgrFusionOperator.get(wnnOperatorId);
+    operatorArray.push(wnnOperator);
+  },
+
+  wnnOperatorArraySize: function(operatorArrayId) {
+    var operatorArray = WebNN.mgrOperatorArray.get(operatorArrayId);
+    return operatorArray.length;
+  },
+
+  webnnCreateOperatorArray: function() {
+    var operatorArray = [];
+    return WebNN.mgrOperatorArray.create(operatorArray);
+  },
+
+  webnnCreateNamedInputs: function() {
+    var inputs = {};
+    return WebNN.mgrNamedInputs.create(inputs);
+  },
+
+  wnnNamedInputsSet: function(namedInputsId, namePtr, inputPtr) {
+    var namedInputs = WebNN.mgrNamedInputs.get(namedInputsId);
+    var name = UTF8ToString(namePtr);
+    var input = WebNN.makeInput(inputPtr);
+    namedInputs[name] = input;
+  },
+
+  webnnCreateNamedOutputs: function() {
+    var outputs = {};
+    return WebNN.mgrNamedOutputs.create(outputs);
+  },
+
+  wnnNamedOutputsSet: function(namedOutputsId, namePtr, resourcePtr) {
+    var namedOutputs = WebNN.mgrNamedOutputs.get(namedOutputsId);
+    var name = UTF8ToString(namePtr);
+    var output = WebNN.makeResource(resourcePtr);
+    namedOutputs[name] = output;
+  },
+
+  webnnCreateNamedOperands: function() {
+    var operands = {};
+    return WebNN.mgrNamedOperands.create(operands);
+  },
+
+  wnnNamedOperandsSet: function(namedOperandsId, namePtr, operandId) {
+    var namedOperands = WebNN.mgrNamedOperands.get(namedOperandsId);
+    var name = UTF8ToString(namePtr);
+    var operand = WebNN.mgrOperand.get(operandId);
+    namedOperands[name] = operand;
+  },
+
+  webnnCreateGraphBuilder: function(contextId) {
+    var context = WebNN.mgrContext.get(contextId);
+    var builder = new MLGraphBuilder(context);
+    return WebNN.mgrGraphBuilder.create(builder);
+  },
+
+  wnnContextComputeSync: function(contextId, graphId, inputsId, outputsId) {
+    var context = WebNN.mgrContext.get(contextId);
+    var graph = WebNN.mgrGraph.get(graphId);
+    var inputs = WebNN.mgrNamedInputs.get(inputsId);
+    var outputs = WebNN.mgrNamedOutputs.get(outputsId);
+    context["compute"](graph, inputs, outputs)
+  },
+  
+};
+
+autoAddDeps(LibraryWebNN, '$WebNN');
+mergeInto(LibraryManager.library, LibraryWebNN);
diff --git a/src/modules.js b/src/modules.js
index f6440b592..f279dd45e 100644
--- a/src/modules.js
+++ b/src/modules.js
@@ -151,6 +151,11 @@ global.LibraryManager = {
       libraries.push('library_html5_webgpu.js');
     }
 
+    if (USE_WEBNN) {
+      libraries.push('library_webnn.js');
+      libraries.push('library_html5_webnn.js');
+    }
+
     if (BOOTSTRAPPING_STRUCT_INFO) {
       libraries = [
         'library_bootstrap.js',
diff --git a/src/settings.js b/src/settings.js
index 16eadb47e..6b28542f8 100644
--- a/src/settings.js
+++ b/src/settings.js
@@ -567,6 +567,10 @@ var GL_PREINITIALIZED_CONTEXT = 0;
 // [link]
 var USE_WEBGPU = 0;
 
+// Enables support for WebNN (via "webnn/webnn.h").
+// [link]
+var USE_WEBNN = 0;
+
 // Enables building of stb-image, a tiny public-domain library for decoding
 // images, allowing decoding of images without using the browser's built-in
 // decoders. The benefit is that this can be done synchronously, however, it
diff --git a/src/shell.js b/src/shell.js
index a74deee14..eb34a5a87 100644
--- a/src/shell.js
+++ b/src/shell.js
@@ -238,14 +238,16 @@ if (ENVIRONMENT_IS_NODE) {
   Module['inspect'] = function () { return '[Emscripten Module object]'; };
 
 #if USE_PTHREADS
-  let nodeWorkerThreads;
-  try {
-    nodeWorkerThreads = require('worker_threads');
-  } catch (e) {
-    console.error('The "worker_threads" module is not supported in this node.js build - perhaps a newer version is needed?');
-    throw e;
+  if (global.Worker === undefined) {
+      let nodeWorkerThreads;
+      try {
+        nodeWorkerThreads = require('worker_threads');
+      } catch (e) {
+        console.error('The "worker_threads" module is not supported in this node.js build - perhaps a newer version is needed?');
+        throw e;
+      }
+      global.Worker = nodeWorkerThreads.Worker;
   }
-  global.Worker = nodeWorkerThreads.Worker;
 #endif
 
 #if WASM == 2
diff --git a/src/struct_info.json b/src/struct_info.json
index 77e30c927..2d20a7dca 100644
--- a/src/struct_info.json
+++ b/src/struct_info.json
@@ -1117,6 +1117,164 @@
             ]
         }
     },
+    {
+        "file": "webnn/webnn.h",
+        "defines": [],
+        "structs": {
+            "WNNArrayBufferView": [
+                "buffer",
+                "byteLength",
+                "byteOffset"
+            ],
+            "WNNBatchNormOptions": [
+                "scale",
+                "bias",
+                "axis",
+                "epsilon",
+                "activation"
+            ],
+            "WNNClampOptions": [
+                "minValue",
+                "maxValue"
+            ],
+            "WNNContextOptions": [
+                "devicePreference",
+                "powerPreference"
+            ],
+            "WNNConvTranspose2dOptions": [
+                "paddingCount",
+                "padding",
+                "stridesCount",
+                "strides",
+                "dilationsCount",
+                "dilations",
+                "outputPaddingCount",
+                "outputPadding",
+                "outputSizesCount",
+                "outputSizes",
+                "autoPad",
+                "groups",
+                "inputLayout",
+                "filterLayout",
+                "bias",
+                "activation"
+            ],
+            "WNNConv2dOptions": [
+                "paddingCount",
+                "padding",
+                "stridesCount",
+                "strides",
+                "dilationsCount",
+                "dilations",
+                "autoPad",
+                "groups",
+                "inputLayout",
+                "filterLayout",
+                "bias",
+                "activation"
+            ],
+            "WNNGemmOptions": [
+                "c",
+                "alpha",
+                "beta",
+                "aTranspose",
+                "bTranspose"
+            ],
+            "WNNGpuBufferView": [
+                "buffer",
+                "id",
+                "generation",
+                "size",
+                "offset"
+            ],
+            "WNNGpuDevice": [
+                "device",
+                "id",
+                "generation"
+            ],
+            "WNNGruOptions": [
+                "bias",
+                "recurrentBias",
+                "initialHiddenState",
+                "resetAfter",
+                "returnSequence",
+                "direction",
+                "layout",
+                "activations"
+            ],
+            "WNNInstanceNormOptions": [
+                "scale",
+                "bias",
+                "epsilon",
+                "layout"
+            ],
+            "WNNLeakyReluOptions": [
+                "alpha"
+            ],
+            "WNNOperandDescriptor": [
+                "type",
+                "dimensions",
+                "dimensionsCount"
+            ],
+            "WNNPadOptions": [
+                "mode",
+                "value"
+            ],
+            "WNNPool2dOptions": [
+                "windowDimensionsCount",
+                "windowDimensions",
+                "paddingCount",
+                "padding",
+                "stridesCount",
+                "strides",
+                "dilationsCount",
+                "dilations",
+                "autoPad",
+                "layout",
+                "roundingType",
+                "outputSizesCount",
+                "outputSizes"
+            ],
+            "WNNReduceOptions": [
+                "axesCount",
+                "axes",
+                "keepDimensions"
+            ],
+            "WNNResample2dOptions": [
+                "mode",
+                "scalesCount",
+                "scales",
+                "sizesCount",
+                "sizes",
+                "axesCount",
+                "axes"
+            ],
+            "WNNSliceOptions": [
+                "axesCount",
+                "axes"
+            ],
+            "WNNSplitOptions": [
+                "axis"
+            ],
+            "WNNSqueezeOptions": [
+                "axesCount",
+                "axes"
+            ],
+            "WNNTransposeOptions": [
+                "permutationCount",
+                "permutation"
+            ],
+            "WNNResource": [
+                "arrayBufferView",
+                "gpuBufferView"
+            ],
+            "WNNInput": [
+                "resource",
+                "dimensions",
+                "dimensionsCount"
+            ]
+        }
+    },
     // ===========================================
     // WebGPU
     //   NOTE: This section is auto-generated.
diff --git a/src/worker.js b/src/worker.js
index 135822910..34c854a40 100644
--- a/src/worker.js
+++ b/src/worker.js
@@ -14,7 +14,8 @@ var Module = {};
 
 #if ENVIRONMENT_MAY_BE_NODE
 // Node.js support
-var ENVIRONMENT_IS_NODE = typeof process === 'object' && typeof process.versions === 'object' && typeof process.versions.node === 'string';
+var ENVIRONMENT_IS_NODE = typeof process === 'object' && typeof process.versions === 'object'
+    && typeof process.versions.node === 'string' && global.Worker === undefined;
 if (ENVIRONMENT_IS_NODE) {
   // Create as web-worker-like an environment as we can.
 
diff --git a/system/include/emscripten/html5_webnn.h b/system/include/emscripten/html5_webnn.h
new file mode 100644
index 000000000..3d5266267
--- /dev/null
+++ b/system/include/emscripten/html5_webnn.h
@@ -0,0 +1,20 @@
+/*
+ * Copyright 2021 The Emscripten Authors.  All rights reserved.
+ * Emscripten is available under two separate licenses, the MIT license and the
+ * University of Illinois/NCSA Open Source License.  Both these licenses can be
+ * found in the LICENSE file.
+ */
+
+#pragma once
+
+#include <webnn/webnn.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+WNNContext emscripten_webnn_create_context(wnn::ContextOptions const* options = nullptr);
+
+#ifdef __cplusplus
+} // ~extern "C"
+#endif
\ No newline at end of file
diff --git a/system/include/webnn/EnumClassBitmasks.h b/system/include/webnn/EnumClassBitmasks.h
new file mode 100644
index 000000000..bdef1df3d
--- /dev/null
+++ b/system/include/webnn/EnumClassBitmasks.h
@@ -0,0 +1,145 @@
+// Copyright 2017 The Dawn Authors
+// Copyright 2021 The WebNN-native Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef WEBNN_ENUM_CLASS_BITMASKS_H_
+#define WEBNN_ENUM_CLASS_BITMASKS_H_
+
+#include <type_traits>
+
+namespace webnn {
+
+    template <typename T>
+    struct IsDawnBitmask {
+        static constexpr bool enable = false;
+    };
+
+    template <typename T, typename Enable = void>
+    struct LowerBitmask {
+        static constexpr bool enable = false;
+    };
+
+    template <typename T>
+    struct LowerBitmask<T, typename std::enable_if<IsDawnBitmask<T>::enable>::type> {
+        static constexpr bool enable = true;
+        using type = T;
+        constexpr static T Lower(T t) {
+            return t;
+        }
+    };
+
+    template <typename T>
+    struct BoolConvertible {
+        using Integral = typename std::underlying_type<T>::type;
+
+        constexpr BoolConvertible(Integral value) : value(value) {
+        }
+        constexpr operator bool() const {
+            return value != 0;
+        }
+        constexpr operator T() const {
+            return static_cast<T>(value);
+        }
+
+        Integral value;
+    };
+
+    template <typename T>
+    struct LowerBitmask<BoolConvertible<T>> {
+        static constexpr bool enable = true;
+        using type = T;
+        static constexpr type Lower(BoolConvertible<T> t) {
+            return t;
+        }
+    };
+
+    template <typename T1,
+              typename T2,
+              typename = typename std::enable_if<LowerBitmask<T1>::enable &&
+                                                 LowerBitmask<T2>::enable>::type>
+    constexpr BoolConvertible<typename LowerBitmask<T1>::type> operator|(T1 left, T2 right) {
+        using T = typename LowerBitmask<T1>::type;
+        using Integral = typename std::underlying_type<T>::type;
+        return static_cast<Integral>(LowerBitmask<T1>::Lower(left)) |
+               static_cast<Integral>(LowerBitmask<T2>::Lower(right));
+    }
+
+    template <typename T1,
+              typename T2,
+              typename = typename std::enable_if<LowerBitmask<T1>::enable &&
+                                                 LowerBitmask<T2>::enable>::type>
+    constexpr BoolConvertible<typename LowerBitmask<T1>::type> operator&(T1 left, T2 right) {
+        using T = typename LowerBitmask<T1>::type;
+        using Integral = typename std::underlying_type<T>::type;
+        return static_cast<Integral>(LowerBitmask<T1>::Lower(left)) &
+               static_cast<Integral>(LowerBitmask<T2>::Lower(right));
+    }
+
+    template <typename T1,
+              typename T2,
+              typename = typename std::enable_if<LowerBitmask<T1>::enable &&
+                                                 LowerBitmask<T2>::enable>::type>
+    constexpr BoolConvertible<typename LowerBitmask<T1>::type> operator^(T1 left, T2 right) {
+        using T = typename LowerBitmask<T1>::type;
+        using Integral = typename std::underlying_type<T>::type;
+        return static_cast<Integral>(LowerBitmask<T1>::Lower(left)) ^
+               static_cast<Integral>(LowerBitmask<T2>::Lower(right));
+    }
+
+    template <typename T1>
+    constexpr BoolConvertible<typename LowerBitmask<T1>::type> operator~(T1 t) {
+        using T = typename LowerBitmask<T1>::type;
+        using Integral = typename std::underlying_type<T>::type;
+        return ~static_cast<Integral>(LowerBitmask<T1>::Lower(t));
+    }
+
+    template <typename T,
+              typename T2,
+              typename = typename std::enable_if<IsDawnBitmask<T>::enable &&
+                                                 LowerBitmask<T2>::enable>::type>
+    constexpr T& operator&=(T& l, T2 right) {
+        T r = LowerBitmask<T2>::Lower(right);
+        l = l & r;
+        return l;
+    }
+
+    template <typename T,
+              typename T2,
+              typename = typename std::enable_if<IsDawnBitmask<T>::enable &&
+                                                 LowerBitmask<T2>::enable>::type>
+    constexpr T& operator|=(T& l, T2 right) {
+        T r = LowerBitmask<T2>::Lower(right);
+        l = l | r;
+        return l;
+    }
+
+    template <typename T,
+              typename T2,
+              typename = typename std::enable_if<IsDawnBitmask<T>::enable &&
+                                                 LowerBitmask<T2>::enable>::type>
+    constexpr T& operator^=(T& l, T2 right) {
+        T r = LowerBitmask<T2>::Lower(right);
+        l = l ^ r;
+        return l;
+    }
+
+    template <typename T>
+    constexpr bool HasZeroOrOneBits(T value) {
+        using Integral = typename std::underlying_type<T>::type;
+        return (static_cast<Integral>(value) & (static_cast<Integral>(value) - 1)) == 0;
+    }
+
+}  // namespace webnn
+
+#endif  // WEBNN_ENUM_CLASS_BITMASKS_H_
diff --git a/system/include/webnn/webnn.h b/system/include/webnn/webnn.h
new file mode 100644
index 000000000..7a97fa44e
--- /dev/null
+++ b/system/include/webnn/webnn.h
@@ -0,0 +1,630 @@
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef WEBNN_H_
+#define WEBNN_H_
+
+#if defined(WEBNN_SHARED_LIBRARY)
+#    if defined(_WIN32)
+#        if defined(WEBNN_IMPLEMENTATION)
+#            define WEBNN_EXPORT __declspec(dllexport)
+#        else
+#            define WEBNN_EXPORT __declspec(dllimport)
+#        endif
+#    else  // defined(_WIN32)
+#        if defined(WEBNN_IMPLEMENTATION)
+#            define WEBNN_EXPORT __attribute__((visibility("default")))
+#        else
+#            define WEBNN_EXPORT
+#        endif
+#    endif  // defined(_WIN32)
+#else       // defined(WEBNN_SHARED_LIBRARY)
+#    define WEBNN_EXPORT
+#endif  // defined(WEBNN_SHARED_LIBRARY)
+
+#include <stdint.h>
+#include <stddef.h>
+#include <stdbool.h>
+
+typedef uint32_t WEBNNFlags;
+
+typedef struct WNNContextImpl* WNNContext;
+typedef struct WNNFusionOperatorImpl* WNNFusionOperator;
+typedef struct WNNGraphImpl* WNNGraph;
+typedef struct WNNGraphBuilderImpl* WNNGraphBuilder;
+typedef struct WNNInstanceImpl* WNNInstance;
+typedef struct WNNNamedInputsImpl* WNNNamedInputs;
+typedef struct WNNNamedOperandsImpl* WNNNamedOperands;
+typedef struct WNNNamedOutputsImpl* WNNNamedOutputs;
+typedef struct WNNOperandImpl* WNNOperand;
+typedef struct WNNOperandArrayImpl* WNNOperandArray;
+typedef struct WNNOperatorArrayImpl* WNNOperatorArray;
+
+typedef enum WNNAutoPad {
+    WNNAutoPad_Explicit = 0x00000000,
+    WNNAutoPad_SameUpper = 0x00000001,
+    WNNAutoPad_SameLower = 0x00000002,
+    WNNAutoPad_Force32 = 0x7FFFFFFF
+} WNNAutoPad;
+
+typedef enum WNNBackendType {
+    WNNBackendType_Null = 0x00000000,
+    WNNBackendType_DirectML = 0x00000001,
+    WNNBackendType_DirectMLX = 0x00000002,
+    WNNBackendType_OpenVINO = 0x00000003,
+    WNNBackendType_OneDNN = 0x00000004,
+    WNNBackendType_MLAS = 0x00000005,
+    WNNBackendType_XNNPACK = 0x00000006,
+    WNNBackendType_NNAPI = 0x00000007,
+    WNNBackendType_Force32 = 0x7FFFFFFF
+} WNNBackendType;
+
+typedef enum WNNConvTranspose2dFilterOperandLayout {
+    WNNConvTranspose2dFilterOperandLayout_Iohw = 0x00000000,
+    WNNConvTranspose2dFilterOperandLayout_Hwoi = 0x00000001,
+    WNNConvTranspose2dFilterOperandLayout_Ohwi = 0x00000002,
+    WNNConvTranspose2dFilterOperandLayout_Force32 = 0x7FFFFFFF
+} WNNConvTranspose2dFilterOperandLayout;
+
+typedef enum WNNConv2dFilterOperandLayout {
+    WNNConv2dFilterOperandLayout_Oihw = 0x00000000,
+    WNNConv2dFilterOperandLayout_Hwio = 0x00000001,
+    WNNConv2dFilterOperandLayout_Ohwi = 0x00000002,
+    WNNConv2dFilterOperandLayout_Ihwo = 0x00000003,
+    WNNConv2dFilterOperandLayout_Force32 = 0x7FFFFFFF
+} WNNConv2dFilterOperandLayout;
+
+typedef enum WNNDevicePreference {
+    WNNDevicePreference_Default = 0x00000000,
+    WNNDevicePreference_Gpu = 0x00000001,
+    WNNDevicePreference_Cpu = 0x00000002,
+    WNNDevicePreference_Force32 = 0x7FFFFFFF
+} WNNDevicePreference;
+
+typedef enum WNNErrorFilter {
+    WNNErrorFilter_None = 0x00000000,
+    WNNErrorFilter_Validation = 0x00000001,
+    WNNErrorFilter_OutOfMemory = 0x00000002,
+    WNNErrorFilter_Force32 = 0x7FFFFFFF
+} WNNErrorFilter;
+
+typedef enum WNNErrorType {
+    WNNErrorType_NoError = 0x00000000,
+    WNNErrorType_Validation = 0x00000001,
+    WNNErrorType_OutOfMemory = 0x00000002,
+    WNNErrorType_Unknown = 0x00000003,
+    WNNErrorType_DeviceLost = 0x00000004,
+    WNNErrorType_Force32 = 0x7FFFFFFF
+} WNNErrorType;
+
+typedef enum WNNInputOperandLayout {
+    WNNInputOperandLayout_Nchw = 0x00000000,
+    WNNInputOperandLayout_Nhwc = 0x00000001,
+    WNNInputOperandLayout_Force32 = 0x7FFFFFFF
+} WNNInputOperandLayout;
+
+typedef enum WNNInterpolationMode {
+    WNNInterpolationMode_NearestNeighbor = 0x00000000,
+    WNNInterpolationMode_Linear = 0x00000001,
+    WNNInterpolationMode_Force32 = 0x7FFFFFFF
+} WNNInterpolationMode;
+
+typedef enum WNNOperandType {
+    WNNOperandType_Float32 = 0x00000000,
+    WNNOperandType_Float16 = 0x00000001,
+    WNNOperandType_Int32 = 0x00000002,
+    WNNOperandType_Uint32 = 0x00000003,
+    WNNOperandType_Int8 = 0x00000004,
+    WNNOperandType_Uint8 = 0x00000005,
+    WNNOperandType_Force32 = 0x7FFFFFFF
+} WNNOperandType;
+
+typedef enum WNNPaddingMode {
+    WNNPaddingMode_Constant = 0x00000000,
+    WNNPaddingMode_Edge = 0x00000001,
+    WNNPaddingMode_Reflection = 0x00000002,
+    WNNPaddingMode_Symmetric = 0x00000003,
+    WNNPaddingMode_Force32 = 0x7FFFFFFF
+} WNNPaddingMode;
+
+typedef enum WNNPowerPreference {
+    WNNPowerPreference_Default = 0x00000000,
+    WNNPowerPreference_High_performance = 0x00000001,
+    WNNPowerPreference_Low_power = 0x00000002,
+    WNNPowerPreference_Force32 = 0x7FFFFFFF
+} WNNPowerPreference;
+
+typedef enum WNNRecurrentNetworkDirection {
+    WNNRecurrentNetworkDirection_Forward = 0x00000000,
+    WNNRecurrentNetworkDirection_Backward = 0x00000001,
+    WNNRecurrentNetworkDirection_Both = 0x00000002,
+    WNNRecurrentNetworkDirection_Force32 = 0x7FFFFFFF
+} WNNRecurrentNetworkDirection;
+
+typedef enum WNNRecurrentNetworkWeightLayout {
+    WNNRecurrentNetworkWeightLayout_Zrn = 0x00000000,
+    WNNRecurrentNetworkWeightLayout_Rzn = 0x00000001,
+    WNNRecurrentNetworkWeightLayout_Force32 = 0x7FFFFFFF
+} WNNRecurrentNetworkWeightLayout;
+
+typedef enum WNNRoundingType {
+    WNNRoundingType_Floor = 0x00000000,
+    WNNRoundingType_Ceil = 0x00000001,
+    WNNRoundingType_Force32 = 0x7FFFFFFF
+} WNNRoundingType;
+
+
+typedef struct WNNArrayBufferView {
+    void * buffer;
+    size_t byteLength;
+    size_t byteOffset;
+} WNNArrayBufferView;
+
+typedef struct WNNBatchNormOptions {
+    WNNOperand scale;
+    WNNOperand bias;
+    uint32_t axis;
+    float epsilon;
+    WNNFusionOperator activation;
+} WNNBatchNormOptions;
+
+typedef struct WNNClampOptions {
+    float minValue;
+    float maxValue;
+} WNNClampOptions;
+
+typedef struct WNNContextOptions {
+    WNNDevicePreference devicePreference;
+    WNNPowerPreference powerPreference;
+} WNNContextOptions;
+
+typedef struct WNNConvTranspose2dOptions {
+    uint32_t paddingCount;
+    int32_t const * padding;
+    uint32_t stridesCount;
+    int32_t const * strides;
+    uint32_t dilationsCount;
+    int32_t const * dilations;
+    uint32_t outputPaddingCount;
+    int32_t const * outputPadding;
+    uint32_t outputSizesCount;
+    int32_t const * outputSizes;
+    WNNAutoPad autoPad;
+    int32_t groups;
+    WNNInputOperandLayout inputLayout;
+    WNNConvTranspose2dFilterOperandLayout filterLayout;
+    WNNOperand bias;
+    WNNFusionOperator activation;
+} WNNConvTranspose2dOptions;
+
+typedef struct WNNConv2dOptions {
+    uint32_t paddingCount;
+    int32_t const * padding;
+    uint32_t stridesCount;
+    int32_t const * strides;
+    uint32_t dilationsCount;
+    int32_t const * dilations;
+    WNNAutoPad autoPad;
+    int32_t groups;
+    WNNInputOperandLayout inputLayout;
+    WNNConv2dFilterOperandLayout filterLayout;
+    WNNOperand bias;
+    WNNFusionOperator activation;
+} WNNConv2dOptions;
+
+typedef struct WNNGemmOptions {
+    WNNOperand c;
+    float alpha;
+    float beta;
+    bool aTranspose;
+    bool bTranspose;
+} WNNGemmOptions;
+
+typedef struct WNNGpuBufferView {
+    void * buffer;
+    uint32_t id;
+    uint32_t generation;
+    size_t size;
+    size_t offset;
+} WNNGpuBufferView;
+
+typedef struct WNNGpuDevice {
+    void * device;
+    uint32_t id;
+    uint32_t generation;
+} WNNGpuDevice;
+
+typedef struct WNNGruOptions {
+    WNNOperand bias;
+    WNNOperand recurrentBias;
+    WNNOperand initialHiddenState;
+    bool resetAfter;
+    bool returnSequence;
+    WNNRecurrentNetworkDirection direction;
+    WNNRecurrentNetworkWeightLayout layout;
+    WNNOperatorArray activations;
+} WNNGruOptions;
+
+typedef struct WNNInstanceDescriptor {
+} WNNInstanceDescriptor;
+
+typedef struct WNNInstanceNormOptions {
+    WNNOperand scale;
+    WNNOperand bias;
+    float epsilon;
+    WNNInputOperandLayout layout;
+} WNNInstanceNormOptions;
+
+typedef struct WNNLeakyReluOptions {
+    float alpha;
+} WNNLeakyReluOptions;
+
+typedef struct WNNOperandDescriptor {
+    WNNOperandType type;
+    int32_t const * dimensions;
+    uint32_t dimensionsCount;
+} WNNOperandDescriptor;
+
+typedef struct WNNPadOptions {
+    WNNPaddingMode mode;
+    float value;
+} WNNPadOptions;
+
+typedef struct WNNPool2dOptions {
+    uint32_t windowDimensionsCount;
+    int32_t const * windowDimensions;
+    uint32_t paddingCount;
+    int32_t const * padding;
+    uint32_t stridesCount;
+    int32_t const * strides;
+    uint32_t dilationsCount;
+    int32_t const * dilations;
+    WNNAutoPad autoPad;
+    WNNInputOperandLayout layout;
+    WNNRoundingType roundingType;
+    uint32_t outputSizesCount;
+    int32_t const * outputSizes;
+} WNNPool2dOptions;
+
+typedef struct WNNReduceOptions {
+    uint32_t axesCount;
+    int32_t const * axes;
+    bool keepDimensions;
+} WNNReduceOptions;
+
+typedef struct WNNResample2dOptions {
+    WNNInterpolationMode mode;
+    uint32_t scalesCount;
+    float const * scales;
+    uint32_t sizesCount;
+    int32_t const * sizes;
+    uint32_t axesCount;
+    int32_t const * axes;
+} WNNResample2dOptions;
+
+typedef struct WNNSliceOptions {
+    uint32_t axesCount;
+    int32_t const * axes;
+} WNNSliceOptions;
+
+typedef struct WNNSplitOptions {
+    int32_t axis;
+} WNNSplitOptions;
+
+typedef struct WNNSqueezeOptions {
+    uint32_t axesCount;
+    int32_t const * axes;
+} WNNSqueezeOptions;
+
+typedef struct WNNTransposeOptions {
+    uint32_t permutationCount;
+    int32_t const * permutation;
+} WNNTransposeOptions;
+
+typedef struct WNNResource {
+    WNNArrayBufferView arrayBufferView;
+    WNNGpuBufferView gpuBufferView;
+} WNNResource;
+
+typedef struct WNNInput {
+    WNNResource resource;
+    int32_t const * dimensions;
+    uint32_t dimensionsCount;
+} WNNInput;
+
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef void (*WNNComputeAsyncCallback)(WNNErrorType type, char const * message, void * userdata);
+typedef void (*WNNErrorCallback)(WNNErrorType type, char const * message, void * userdata);
+
+typedef void (*WebnnProc)(void);
+
+#if !defined(WEBNN_SKIP_PROCS)
+
+typedef WNNGraphBuilder (*WebnnProcCreateGraphBuilder)(WNNContext context);
+typedef WNNNamedInputs (*WebnnProcCreateNamedInputs)();
+typedef WNNNamedOperands (*WebnnProcCreateNamedOperands)();
+typedef WNNNamedOutputs (*WebnnProcCreateNamedOutputs)();
+typedef WNNOperatorArray (*WebnnProcCreateOperatorArray)();
+
+// Procs of Context
+typedef void (*WebnnProcContextCompute)(WNNContext context, WNNGraph graph, WNNNamedInputs inputs, WNNNamedOutputs outputs, WNNComputeAsyncCallback callback, void * userdata);
+typedef void (*WebnnProcContextComputeSync)(WNNContext context, WNNGraph graph, WNNNamedInputs inputs, WNNNamedOutputs outputs);
+typedef void (*WebnnProcContextInjectError)(WNNContext context, WNNErrorType type, char const * message);
+typedef bool (*WebnnProcContextPopErrorScope)(WNNContext context, WNNErrorCallback callback, void * userdata);
+typedef void (*WebnnProcContextPushErrorScope)(WNNContext context, WNNErrorFilter filter);
+typedef void (*WebnnProcContextSetUncapturedErrorCallback)(WNNContext context, WNNErrorCallback callback, void * userdata);
+typedef void (*WebnnProcContextReference)(WNNContext context);
+typedef void (*WebnnProcContextRelease)(WNNContext context);
+
+// Procs of FusionOperator
+typedef void (*WebnnProcFusionOperatorReference)(WNNFusionOperator fusionOperator);
+typedef void (*WebnnProcFusionOperatorRelease)(WNNFusionOperator fusionOperator);
+
+// Procs of Graph
+typedef void (*WebnnProcGraphReference)(WNNGraph graph);
+typedef void (*WebnnProcGraphRelease)(WNNGraph graph);
+
+// Procs of GraphBuilder
+typedef WNNOperand (*WebnnProcGraphBuilderAbs)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderAdd)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderAveragePool2d)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNPool2dOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderBatchNorm)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand mean, WNNOperand variance, WNNBatchNormOptions const * options);
+typedef WNNGraph (*WebnnProcGraphBuilderBuild)(WNNGraphBuilder graphBuilder, WNNNamedOperands namedOperands);
+typedef WNNOperand (*WebnnProcGraphBuilderCeil)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderClamp)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNClampOptions const * options);
+typedef WNNFusionOperator (*WebnnProcGraphBuilderClampOperator)(WNNGraphBuilder graphBuilder, WNNClampOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderConcat)(WNNGraphBuilder graphBuilder, uint32_t inputsCount, WNNOperand const * inputs, uint32_t axis);
+typedef WNNOperand (*WebnnProcGraphBuilderConstant)(WNNGraphBuilder graphBuilder, WNNOperandDescriptor const * desc, WNNArrayBufferView const * value);
+typedef WNNOperand (*WebnnProcGraphBuilderConstantWithGpuBuffer)(WNNGraphBuilder graphBuilder, WNNOperandDescriptor const * desc, WNNGpuBufferView const * value);
+typedef WNNOperand (*WebnnProcGraphBuilderConvTranspose2d)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand filter, WNNConvTranspose2dOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderConv2d)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand filter, WNNConv2dOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderCos)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderDiv)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderExp)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderFloor)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderGemm)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b, WNNGemmOptions const * options);
+typedef WNNOperandArray (*WebnnProcGraphBuilderGru)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand weight, WNNOperand recurrentWeight, int32_t steps, int32_t hiddenSize, WNNGruOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderHardSwish)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNFusionOperator (*WebnnProcGraphBuilderHardSwishOperator)(WNNGraphBuilder graphBuilder);
+typedef WNNOperand (*WebnnProcGraphBuilderInput)(WNNGraphBuilder graphBuilder, char const * name, WNNOperandDescriptor const * desc);
+typedef WNNOperand (*WebnnProcGraphBuilderInstanceNorm)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNInstanceNormOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderL2Pool2d)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNPool2dOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderLeakyRelu)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNLeakyReluOptions const * options);
+typedef WNNFusionOperator (*WebnnProcGraphBuilderLeakyReluOperator)(WNNGraphBuilder graphBuilder, WNNLeakyReluOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderLog)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderMatmul)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderMax)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderMaxPool2d)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNPool2dOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderMin)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderMul)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderNeg)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderPad)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand padding, WNNPadOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderPow)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceArgMax)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceArgMin)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceL1)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceL2)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceMax)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceMean)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceMin)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceProduct)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReduceSum)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderRelu)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNFusionOperator (*WebnnProcGraphBuilderReluOperator)(WNNGraphBuilder graphBuilder);
+typedef WNNOperand (*WebnnProcGraphBuilderResample2d)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNResample2dOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderReshape)(WNNGraphBuilder graphBuilder, WNNOperand input, int32_t const * newShape, uint32_t newShapeCount);
+typedef WNNOperand (*WebnnProcGraphBuilderSigmoid)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNFusionOperator (*WebnnProcGraphBuilderSigmoidOperator)(WNNGraphBuilder graphBuilder);
+typedef WNNOperand (*WebnnProcGraphBuilderSin)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderSlice)(WNNGraphBuilder graphBuilder, WNNOperand input, int32_t const * starts, uint32_t startsCount, int32_t const * sizes, uint32_t sizesCount, WNNSliceOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderSoftmax)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperandArray (*WebnnProcGraphBuilderSplit)(WNNGraphBuilder graphBuilder, WNNOperand input, uint32_t const * splits, uint32_t splitsCount, WNNSplitOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderSqueeze)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNSqueezeOptions const * options);
+typedef WNNOperand (*WebnnProcGraphBuilderSub)(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+typedef WNNOperand (*WebnnProcGraphBuilderTan)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNOperand (*WebnnProcGraphBuilderTanh)(WNNGraphBuilder graphBuilder, WNNOperand input);
+typedef WNNFusionOperator (*WebnnProcGraphBuilderTanhOperator)(WNNGraphBuilder graphBuilder);
+typedef WNNOperand (*WebnnProcGraphBuilderTranspose)(WNNGraphBuilder graphBuilder, WNNOperand input, WNNTransposeOptions const * options);
+typedef void (*WebnnProcGraphBuilderReference)(WNNGraphBuilder graphBuilder);
+typedef void (*WebnnProcGraphBuilderRelease)(WNNGraphBuilder graphBuilder);
+
+// Procs of Instance
+typedef WNNContext (*WebnnProcInstanceCreateContext)(WNNInstance instance, WNNContextOptions const * options);
+typedef WNNContext (*WebnnProcInstanceCreateContextWithGpuDevice)(WNNInstance instance, WNNGpuDevice const * gpuDevice);
+typedef WNNGraphBuilder (*WebnnProcInstanceCreateGraphBuilder)(WNNInstance instance, WNNContext context);
+typedef WNNNamedInputs (*WebnnProcInstanceCreateNamedInputs)(WNNInstance instance);
+typedef WNNNamedOperands (*WebnnProcInstanceCreateNamedOperands)(WNNInstance instance);
+typedef WNNNamedOutputs (*WebnnProcInstanceCreateNamedOutputs)(WNNInstance instance);
+typedef WNNOperatorArray (*WebnnProcInstanceCreateOperatorArray)(WNNInstance instance);
+typedef void (*WebnnProcInstanceReference)(WNNInstance instance);
+typedef void (*WebnnProcInstanceRelease)(WNNInstance instance);
+
+// Procs of NamedInputs
+typedef void (*WebnnProcNamedInputsSet)(WNNNamedInputs namedInputs, char const * name, WNNInput const * input);
+typedef void (*WebnnProcNamedInputsReference)(WNNNamedInputs namedInputs);
+typedef void (*WebnnProcNamedInputsRelease)(WNNNamedInputs namedInputs);
+
+// Procs of NamedOperands
+typedef void (*WebnnProcNamedOperandsSet)(WNNNamedOperands namedOperands, char const * name, WNNOperand operand);
+typedef void (*WebnnProcNamedOperandsReference)(WNNNamedOperands namedOperands);
+typedef void (*WebnnProcNamedOperandsRelease)(WNNNamedOperands namedOperands);
+
+// Procs of NamedOutputs
+typedef void (*WebnnProcNamedOutputsGet)(WNNNamedOutputs namedOutputs, char const * name, WNNArrayBufferView * resource);
+typedef void (*WebnnProcNamedOutputsSet)(WNNNamedOutputs namedOutputs, char const * name, WNNResource const * resource);
+typedef void (*WebnnProcNamedOutputsReference)(WNNNamedOutputs namedOutputs);
+typedef void (*WebnnProcNamedOutputsRelease)(WNNNamedOutputs namedOutputs);
+
+// Procs of Operand
+typedef void (*WebnnProcOperandReference)(WNNOperand operand);
+typedef void (*WebnnProcOperandRelease)(WNNOperand operand);
+
+// Procs of OperandArray
+typedef WNNOperand (*WebnnProcOperandArrayGet)(WNNOperandArray operandArray, size_t index);
+typedef size_t (*WebnnProcOperandArraySize)(WNNOperandArray operandArray);
+typedef void (*WebnnProcOperandArrayReference)(WNNOperandArray operandArray);
+typedef void (*WebnnProcOperandArrayRelease)(WNNOperandArray operandArray);
+
+// Procs of OperatorArray
+typedef WNNFusionOperator (*WebnnProcOperatorArrayGet)(WNNOperatorArray operatorArray, size_t index);
+typedef void (*WebnnProcOperatorArraySet)(WNNOperatorArray operatorArray, WNNFusionOperator wnnOperator);
+typedef size_t (*WebnnProcOperatorArraySize)(WNNOperatorArray operatorArray);
+typedef void (*WebnnProcOperatorArrayReference)(WNNOperatorArray operatorArray);
+typedef void (*WebnnProcOperatorArrayRelease)(WNNOperatorArray operatorArray);
+
+#endif  // !defined(WEBNN_SKIP_PROCS)
+
+#if !defined(WEBNN_SKIP_DECLARATIONS)
+
+WEBNN_EXPORT WNNGraphBuilder webnnCreateGraphBuilder(WNNContext context);
+WEBNN_EXPORT WNNNamedInputs webnnCreateNamedInputs();
+WEBNN_EXPORT WNNNamedOperands webnnCreateNamedOperands();
+WEBNN_EXPORT WNNNamedOutputs webnnCreateNamedOutputs();
+WEBNN_EXPORT WNNOperatorArray webnnCreateOperatorArray();
+
+// Methods of Context
+WEBNN_EXPORT void wnnContextCompute(WNNContext context, WNNGraph graph, WNNNamedInputs inputs, WNNNamedOutputs outputs, WNNComputeAsyncCallback callback, void * userdata);
+WEBNN_EXPORT void wnnContextComputeSync(WNNContext context, WNNGraph graph, WNNNamedInputs inputs, WNNNamedOutputs outputs);
+WEBNN_EXPORT void wnnContextInjectError(WNNContext context, WNNErrorType type, char const * message);
+WEBNN_EXPORT bool wnnContextPopErrorScope(WNNContext context, WNNErrorCallback callback, void * userdata);
+WEBNN_EXPORT void wnnContextPushErrorScope(WNNContext context, WNNErrorFilter filter);
+WEBNN_EXPORT void wnnContextSetUncapturedErrorCallback(WNNContext context, WNNErrorCallback callback, void * userdata);
+WEBNN_EXPORT void wnnContextReference(WNNContext context);
+WEBNN_EXPORT void wnnContextRelease(WNNContext context);
+
+// Methods of FusionOperator
+WEBNN_EXPORT void wnnFusionOperatorReference(WNNFusionOperator fusionOperator);
+WEBNN_EXPORT void wnnFusionOperatorRelease(WNNFusionOperator fusionOperator);
+
+// Methods of Graph
+WEBNN_EXPORT void wnnGraphReference(WNNGraph graph);
+WEBNN_EXPORT void wnnGraphRelease(WNNGraph graph);
+
+// Methods of GraphBuilder
+WEBNN_EXPORT WNNOperand wnnGraphBuilderAbs(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderAdd(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderAveragePool2d(WNNGraphBuilder graphBuilder, WNNOperand input, WNNPool2dOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderBatchNorm(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand mean, WNNOperand variance, WNNBatchNormOptions const * options);
+WEBNN_EXPORT WNNGraph wnnGraphBuilderBuild(WNNGraphBuilder graphBuilder, WNNNamedOperands namedOperands);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderCeil(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderClamp(WNNGraphBuilder graphBuilder, WNNOperand input, WNNClampOptions const * options);
+WEBNN_EXPORT WNNFusionOperator wnnGraphBuilderClampOperator(WNNGraphBuilder graphBuilder, WNNClampOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderConcat(WNNGraphBuilder graphBuilder, uint32_t inputsCount, WNNOperand const * inputs, uint32_t axis);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderConstant(WNNGraphBuilder graphBuilder, WNNOperandDescriptor const * desc, WNNArrayBufferView const * value);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderConstantWithGpuBuffer(WNNGraphBuilder graphBuilder, WNNOperandDescriptor const * desc, WNNGpuBufferView const * value);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderConvTranspose2d(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand filter, WNNConvTranspose2dOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderConv2d(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand filter, WNNConv2dOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderCos(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderDiv(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderExp(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderFloor(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderGemm(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b, WNNGemmOptions const * options);
+WEBNN_EXPORT WNNOperandArray wnnGraphBuilderGru(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand weight, WNNOperand recurrentWeight, int32_t steps, int32_t hiddenSize, WNNGruOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderHardSwish(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNFusionOperator wnnGraphBuilderHardSwishOperator(WNNGraphBuilder graphBuilder);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderInput(WNNGraphBuilder graphBuilder, char const * name, WNNOperandDescriptor const * desc);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderInstanceNorm(WNNGraphBuilder graphBuilder, WNNOperand input, WNNInstanceNormOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderL2Pool2d(WNNGraphBuilder graphBuilder, WNNOperand input, WNNPool2dOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderLeakyRelu(WNNGraphBuilder graphBuilder, WNNOperand input, WNNLeakyReluOptions const * options);
+WEBNN_EXPORT WNNFusionOperator wnnGraphBuilderLeakyReluOperator(WNNGraphBuilder graphBuilder, WNNLeakyReluOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderLog(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderMatmul(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderMax(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderMaxPool2d(WNNGraphBuilder graphBuilder, WNNOperand input, WNNPool2dOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderMin(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderMul(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderNeg(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderPad(WNNGraphBuilder graphBuilder, WNNOperand input, WNNOperand padding, WNNPadOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderPow(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceArgMax(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceArgMin(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceL1(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceL2(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceMax(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceMean(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceMin(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceProduct(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReduceSum(WNNGraphBuilder graphBuilder, WNNOperand input, WNNReduceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderRelu(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNFusionOperator wnnGraphBuilderReluOperator(WNNGraphBuilder graphBuilder);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderResample2d(WNNGraphBuilder graphBuilder, WNNOperand input, WNNResample2dOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderReshape(WNNGraphBuilder graphBuilder, WNNOperand input, int32_t const * newShape, uint32_t newShapeCount);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderSigmoid(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNFusionOperator wnnGraphBuilderSigmoidOperator(WNNGraphBuilder graphBuilder);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderSin(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderSlice(WNNGraphBuilder graphBuilder, WNNOperand input, int32_t const * starts, uint32_t startsCount, int32_t const * sizes, uint32_t sizesCount, WNNSliceOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderSoftmax(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperandArray wnnGraphBuilderSplit(WNNGraphBuilder graphBuilder, WNNOperand input, uint32_t const * splits, uint32_t splitsCount, WNNSplitOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderSqueeze(WNNGraphBuilder graphBuilder, WNNOperand input, WNNSqueezeOptions const * options);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderSub(WNNGraphBuilder graphBuilder, WNNOperand a, WNNOperand b);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderTan(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderTanh(WNNGraphBuilder graphBuilder, WNNOperand input);
+WEBNN_EXPORT WNNFusionOperator wnnGraphBuilderTanhOperator(WNNGraphBuilder graphBuilder);
+WEBNN_EXPORT WNNOperand wnnGraphBuilderTranspose(WNNGraphBuilder graphBuilder, WNNOperand input, WNNTransposeOptions const * options);
+WEBNN_EXPORT void wnnGraphBuilderReference(WNNGraphBuilder graphBuilder);
+WEBNN_EXPORT void wnnGraphBuilderRelease(WNNGraphBuilder graphBuilder);
+
+// Methods of Instance
+WEBNN_EXPORT WNNContext wnnInstanceCreateContext(WNNInstance instance, WNNContextOptions const * options);
+WEBNN_EXPORT WNNContext wnnInstanceCreateContextWithGpuDevice(WNNInstance instance, WNNGpuDevice const * gpuDevice);
+WEBNN_EXPORT WNNGraphBuilder wnnInstanceCreateGraphBuilder(WNNInstance instance, WNNContext context);
+WEBNN_EXPORT WNNNamedInputs wnnInstanceCreateNamedInputs(WNNInstance instance);
+WEBNN_EXPORT WNNNamedOperands wnnInstanceCreateNamedOperands(WNNInstance instance);
+WEBNN_EXPORT WNNNamedOutputs wnnInstanceCreateNamedOutputs(WNNInstance instance);
+WEBNN_EXPORT WNNOperatorArray wnnInstanceCreateOperatorArray(WNNInstance instance);
+WEBNN_EXPORT void wnnInstanceReference(WNNInstance instance);
+WEBNN_EXPORT void wnnInstanceRelease(WNNInstance instance);
+
+// Methods of NamedInputs
+WEBNN_EXPORT void wnnNamedInputsSet(WNNNamedInputs namedInputs, char const * name, WNNInput const * input);
+WEBNN_EXPORT void wnnNamedInputsReference(WNNNamedInputs namedInputs);
+WEBNN_EXPORT void wnnNamedInputsRelease(WNNNamedInputs namedInputs);
+
+// Methods of NamedOperands
+WEBNN_EXPORT void wnnNamedOperandsSet(WNNNamedOperands namedOperands, char const * name, WNNOperand operand);
+WEBNN_EXPORT void wnnNamedOperandsReference(WNNNamedOperands namedOperands);
+WEBNN_EXPORT void wnnNamedOperandsRelease(WNNNamedOperands namedOperands);
+
+// Methods of NamedOutputs
+WEBNN_EXPORT void wnnNamedOutputsGet(WNNNamedOutputs namedOutputs, char const * name, WNNArrayBufferView * resource);
+WEBNN_EXPORT void wnnNamedOutputsSet(WNNNamedOutputs namedOutputs, char const * name, WNNResource const * resource);
+WEBNN_EXPORT void wnnNamedOutputsReference(WNNNamedOutputs namedOutputs);
+WEBNN_EXPORT void wnnNamedOutputsRelease(WNNNamedOutputs namedOutputs);
+
+// Methods of Operand
+WEBNN_EXPORT void wnnOperandReference(WNNOperand operand);
+WEBNN_EXPORT void wnnOperandRelease(WNNOperand operand);
+
+// Methods of OperandArray
+WEBNN_EXPORT WNNOperand wnnOperandArrayGet(WNNOperandArray operandArray, size_t index);
+WEBNN_EXPORT size_t wnnOperandArraySize(WNNOperandArray operandArray);
+WEBNN_EXPORT void wnnOperandArrayReference(WNNOperandArray operandArray);
+WEBNN_EXPORT void wnnOperandArrayRelease(WNNOperandArray operandArray);
+
+// Methods of OperatorArray
+WEBNN_EXPORT WNNFusionOperator wnnOperatorArrayGet(WNNOperatorArray operatorArray, size_t index);
+WEBNN_EXPORT void wnnOperatorArraySet(WNNOperatorArray operatorArray, WNNFusionOperator wnnOperator);
+WEBNN_EXPORT size_t wnnOperatorArraySize(WNNOperatorArray operatorArray);
+WEBNN_EXPORT void wnnOperatorArrayReference(WNNOperatorArray operatorArray);
+WEBNN_EXPORT void wnnOperatorArrayRelease(WNNOperatorArray operatorArray);
+
+#endif  // !defined(WEBNN_SKIP_DECLARATIONS)
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // WEBNN_H_
diff --git a/system/include/webnn/webnn_cpp.h b/system/include/webnn/webnn_cpp.h
new file mode 100644
index 000000000..f13287eb2
--- /dev/null
+++ b/system/include/webnn/webnn_cpp.h
@@ -0,0 +1,637 @@
+#ifndef WEBNN_CPP_H_
+#define WEBNN_CPP_H_
+
+#include "webnn/webnn.h"
+#include "webnn/EnumClassBitmasks.h"
+
+#include <limits>
+
+namespace wnn {
+
+    enum class AutoPad : uint32_t {
+        Explicit = 0x00000000,
+        SameUpper = 0x00000001,
+        SameLower = 0x00000002,
+    };
+
+    enum class BackendType : uint32_t {
+        Null = 0x00000000,
+        DirectML = 0x00000001,
+        DirectMLX = 0x00000002,
+        OpenVINO = 0x00000003,
+        OneDNN = 0x00000004,
+        MLAS = 0x00000005,
+        XNNPACK = 0x00000006,
+        NNAPI = 0x00000007,
+    };
+
+    enum class ConvTranspose2dFilterOperandLayout : uint32_t {
+        Iohw = 0x00000000,
+        Hwoi = 0x00000001,
+        Ohwi = 0x00000002,
+    };
+
+    enum class Conv2dFilterOperandLayout : uint32_t {
+        Oihw = 0x00000000,
+        Hwio = 0x00000001,
+        Ohwi = 0x00000002,
+        Ihwo = 0x00000003,
+    };
+
+    enum class DevicePreference : uint32_t {
+        Default = 0x00000000,
+        Gpu = 0x00000001,
+        Cpu = 0x00000002,
+    };
+
+    enum class ErrorFilter : uint32_t {
+        None = 0x00000000,
+        Validation = 0x00000001,
+        OutOfMemory = 0x00000002,
+    };
+
+    enum class ErrorType : uint32_t {
+        NoError = 0x00000000,
+        Validation = 0x00000001,
+        OutOfMemory = 0x00000002,
+        Unknown = 0x00000003,
+        DeviceLost = 0x00000004,
+    };
+
+    enum class InputOperandLayout : uint32_t {
+        Nchw = 0x00000000,
+        Nhwc = 0x00000001,
+    };
+
+    enum class InterpolationMode : uint32_t {
+        NearestNeighbor = 0x00000000,
+        Linear = 0x00000001,
+    };
+
+    enum class OperandType : uint32_t {
+        Float32 = 0x00000000,
+        Float16 = 0x00000001,
+        Int32 = 0x00000002,
+        Uint32 = 0x00000003,
+        Int8 = 0x00000004,
+        Uint8 = 0x00000005,
+    };
+
+    enum class PaddingMode : uint32_t {
+        Constant = 0x00000000,
+        Edge = 0x00000001,
+        Reflection = 0x00000002,
+        Symmetric = 0x00000003,
+    };
+
+    enum class PowerPreference : uint32_t {
+        Default = 0x00000000,
+        High_performance = 0x00000001,
+        Low_power = 0x00000002,
+    };
+
+    enum class RecurrentNetworkDirection : uint32_t {
+        Forward = 0x00000000,
+        Backward = 0x00000001,
+        Both = 0x00000002,
+    };
+
+    enum class RecurrentNetworkWeightLayout : uint32_t {
+        Zrn = 0x00000000,
+        Rzn = 0x00000001,
+    };
+
+    enum class RoundingType : uint32_t {
+        Floor = 0x00000000,
+        Ceil = 0x00000001,
+    };
+
+
+
+
+    using Proc = WebnnProc;
+    using ComputeAsyncCallback = WNNComputeAsyncCallback;
+    using ErrorCallback = WNNErrorCallback;
+
+    class Context;
+    class FusionOperator;
+    class Graph;
+    class GraphBuilder;
+    class Instance;
+    class NamedInputs;
+    class NamedOperands;
+    class NamedOutputs;
+    class Operand;
+    class OperandArray;
+    class OperatorArray;
+
+    struct ArrayBufferView;
+    struct BatchNormOptions;
+    struct ClampOptions;
+    struct ContextOptions;
+    struct ConvTranspose2dOptions;
+    struct Conv2dOptions;
+    struct GemmOptions;
+    struct GpuBufferView;
+    struct GpuDevice;
+    struct GruOptions;
+    struct InstanceDescriptor;
+    struct InstanceNormOptions;
+    struct LeakyReluOptions;
+    struct OperandDescriptor;
+    struct PadOptions;
+    struct Pool2dOptions;
+    struct ReduceOptions;
+    struct Resample2dOptions;
+    struct SliceOptions;
+    struct SplitOptions;
+    struct SqueezeOptions;
+    struct TransposeOptions;
+    struct Resource;
+    struct Input;
+
+    template<typename Derived, typename CType>
+    class ObjectBase {
+      public:
+        ObjectBase() = default;
+        ObjectBase(CType handle): mHandle(handle) {
+            if (mHandle) Derived::WebnnReference(mHandle);
+        }
+        ~ObjectBase() {
+            if (mHandle) Derived::WebnnRelease(mHandle);
+        }
+
+        ObjectBase(ObjectBase const& other)
+            : ObjectBase(other.GetHandle()) {
+        }
+        Derived& operator=(ObjectBase const& other) {
+            if (&other != this) {
+                if (mHandle) Derived::WebnnRelease(mHandle);
+                mHandle = other.mHandle;
+                if (mHandle) Derived::WebnnReference(mHandle);
+            }
+
+            return static_cast<Derived&>(*this);
+        }
+
+        ObjectBase(ObjectBase&& other) {
+            mHandle = other.mHandle;
+            other.mHandle = 0;
+        }
+        Derived& operator=(ObjectBase&& other) {
+            if (&other != this) {
+                if (mHandle) Derived::WebnnRelease(mHandle);
+                mHandle = other.mHandle;
+                other.mHandle = 0;
+            }
+
+            return static_cast<Derived&>(*this);
+        }
+
+        ObjectBase(std::nullptr_t) {}
+        Derived& operator=(std::nullptr_t) {
+            if (mHandle != nullptr) {
+                Derived::WebnnRelease(mHandle);
+                mHandle = nullptr;
+            }
+            return static_cast<Derived&>(*this);
+        }
+
+        bool operator==(std::nullptr_t) const {
+            return mHandle == nullptr;
+        }
+        bool operator!=(std::nullptr_t) const {
+            return mHandle != nullptr;
+        }
+
+        explicit operator bool() const {
+            return mHandle != nullptr;
+        }
+        CType GetHandle() const {
+            return mHandle;
+        }
+        CType Release() {
+            CType result = mHandle;
+            mHandle = 0;
+            return result;
+        }
+        static Derived Acquire(CType handle) {
+            Derived result;
+            result.mHandle = handle;
+            return result;
+        }
+
+      protected:
+        CType mHandle = nullptr;
+    };
+
+
+
+    class Context : public ObjectBase<Context, WNNContext> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        void Compute(Graph const& graph, NamedInputs const& inputs, NamedOutputs const& outputs, ComputeAsyncCallback callback, void * userdata) const;
+        void ComputeSync(Graph const& graph, NamedInputs const& inputs, NamedOutputs const& outputs) const;
+        void InjectError(ErrorType type, char const * message) const;
+        bool PopErrorScope(ErrorCallback callback, void * userdata) const;
+        void PushErrorScope(ErrorFilter filter) const;
+        void SetUncapturedErrorCallback(ErrorCallback callback, void * userdata) const;
+
+      private:
+        friend ObjectBase<Context, WNNContext>;
+        static void WebnnReference(WNNContext handle);
+        static void WebnnRelease(WNNContext handle);
+    };
+
+    class FusionOperator : public ObjectBase<FusionOperator, WNNFusionOperator> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+
+      private:
+        friend ObjectBase<FusionOperator, WNNFusionOperator>;
+        static void WebnnReference(WNNFusionOperator handle);
+        static void WebnnRelease(WNNFusionOperator handle);
+    };
+
+    class Graph : public ObjectBase<Graph, WNNGraph> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+
+      private:
+        friend ObjectBase<Graph, WNNGraph>;
+        static void WebnnReference(WNNGraph handle);
+        static void WebnnRelease(WNNGraph handle);
+    };
+
+    class GraphBuilder : public ObjectBase<GraphBuilder, WNNGraphBuilder> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        Operand Abs(Operand const& input) const;
+        Operand Add(Operand const& a, Operand const& b) const;
+        Operand AveragePool2d(Operand const& input, Pool2dOptions const * options = nullptr) const;
+        Operand BatchNorm(Operand const& input, Operand const& mean, Operand const& variance, BatchNormOptions const * options = nullptr) const;
+        Graph Build(NamedOperands const& namedOperands) const;
+        Operand Ceil(Operand const& input) const;
+        Operand Clamp(Operand const& input, ClampOptions const * options = nullptr) const;
+        FusionOperator ClampOperator(ClampOptions const * options = nullptr) const;
+        Operand Concat(uint32_t inputsCount, Operand const * inputs, uint32_t axis) const;
+        Operand Constant(OperandDescriptor const * desc, ArrayBufferView const * value) const;
+        Operand ConstantWithGpuBuffer(OperandDescriptor const * desc, GpuBufferView const * value) const;
+        Operand ConvTranspose2d(Operand const& input, Operand const& filter, ConvTranspose2dOptions const * options = nullptr) const;
+        Operand Conv2d(Operand const& input, Operand const& filter, Conv2dOptions const * options = nullptr) const;
+        Operand Cos(Operand const& input) const;
+        Operand Div(Operand const& a, Operand const& b) const;
+        Operand Exp(Operand const& input) const;
+        Operand Floor(Operand const& input) const;
+        Operand Gemm(Operand const& a, Operand const& b, GemmOptions const * options = nullptr) const;
+        OperandArray Gru(Operand const& input, Operand const& weight, Operand const& recurrentWeight, int32_t steps, int32_t hiddenSize, GruOptions const * options = nullptr) const;
+        Operand HardSwish(Operand const& input) const;
+        FusionOperator HardSwishOperator() const;
+        Operand Input(char const * name, OperandDescriptor const * desc) const;
+        Operand InstanceNorm(Operand const& input, InstanceNormOptions const * options = nullptr) const;
+        Operand L2Pool2d(Operand const& input, Pool2dOptions const * options = nullptr) const;
+        Operand LeakyRelu(Operand const& input, LeakyReluOptions const * options = nullptr) const;
+        FusionOperator LeakyReluOperator(LeakyReluOptions const * options = nullptr) const;
+        Operand Log(Operand const& input) const;
+        Operand Matmul(Operand const& a, Operand const& b) const;
+        Operand Max(Operand const& a, Operand const& b) const;
+        Operand MaxPool2d(Operand const& input, Pool2dOptions const * options = nullptr) const;
+        Operand Min(Operand const& a, Operand const& b) const;
+        Operand Mul(Operand const& a, Operand const& b) const;
+        Operand Neg(Operand const& input) const;
+        Operand Pad(Operand const& input, Operand const& padding, PadOptions const * options = nullptr) const;
+        Operand Pow(Operand const& a, Operand const& b) const;
+        Operand ReduceArgMax(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceArgMin(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceL1(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceL2(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceMax(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceMean(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceMin(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceProduct(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand ReduceSum(Operand const& input, ReduceOptions const * options = nullptr) const;
+        Operand Relu(Operand const& input) const;
+        FusionOperator ReluOperator() const;
+        Operand Resample2d(Operand const& input, Resample2dOptions const * options = nullptr) const;
+        Operand Reshape(Operand const& input, int32_t const * newShape, uint32_t newShapeCount) const;
+        Operand Sigmoid(Operand const& input) const;
+        FusionOperator SigmoidOperator() const;
+        Operand Sin(Operand const& input) const;
+        Operand Slice(Operand const& input, int32_t const * starts, uint32_t startsCount, int32_t const * sizes, uint32_t sizesCount, SliceOptions const * options = nullptr) const;
+        Operand Softmax(Operand const& input) const;
+        OperandArray Split(Operand const& input, uint32_t const * splits, uint32_t splitsCount, SplitOptions const * options = nullptr) const;
+        Operand Squeeze(Operand const& input, SqueezeOptions const * options = nullptr) const;
+        Operand Sub(Operand const& a, Operand const& b) const;
+        Operand Tan(Operand const& input) const;
+        Operand Tanh(Operand const& input) const;
+        FusionOperator TanhOperator() const;
+        Operand Transpose(Operand const& input, TransposeOptions const * options = nullptr) const;
+
+      private:
+        friend ObjectBase<GraphBuilder, WNNGraphBuilder>;
+        static void WebnnReference(WNNGraphBuilder handle);
+        static void WebnnRelease(WNNGraphBuilder handle);
+    };
+
+    class Instance : public ObjectBase<Instance, WNNInstance> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        Context CreateContext(ContextOptions const * options = nullptr) const;
+        Context CreateContextWithGpuDevice(GpuDevice const * gpuDevice) const;
+        GraphBuilder CreateGraphBuilder(Context const& context) const;
+        NamedInputs CreateNamedInputs() const;
+        NamedOperands CreateNamedOperands() const;
+        NamedOutputs CreateNamedOutputs() const;
+        OperatorArray CreateOperatorArray() const;
+
+      private:
+        friend ObjectBase<Instance, WNNInstance>;
+        static void WebnnReference(WNNInstance handle);
+        static void WebnnRelease(WNNInstance handle);
+    };
+
+    class NamedInputs : public ObjectBase<NamedInputs, WNNNamedInputs> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        void Set(char const * name, Input const * input) const;
+
+      private:
+        friend ObjectBase<NamedInputs, WNNNamedInputs>;
+        static void WebnnReference(WNNNamedInputs handle);
+        static void WebnnRelease(WNNNamedInputs handle);
+    };
+
+    class NamedOperands : public ObjectBase<NamedOperands, WNNNamedOperands> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        void Set(char const * name, Operand const& operand) const;
+
+      private:
+        friend ObjectBase<NamedOperands, WNNNamedOperands>;
+        static void WebnnReference(WNNNamedOperands handle);
+        static void WebnnRelease(WNNNamedOperands handle);
+    };
+
+    class NamedOutputs : public ObjectBase<NamedOutputs, WNNNamedOutputs> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        void Get(char const * name, ArrayBufferView * resource) const;
+        void Set(char const * name, Resource const * resource) const;
+
+      private:
+        friend ObjectBase<NamedOutputs, WNNNamedOutputs>;
+        static void WebnnReference(WNNNamedOutputs handle);
+        static void WebnnRelease(WNNNamedOutputs handle);
+    };
+
+    class Operand : public ObjectBase<Operand, WNNOperand> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+
+      private:
+        friend ObjectBase<Operand, WNNOperand>;
+        static void WebnnReference(WNNOperand handle);
+        static void WebnnRelease(WNNOperand handle);
+    };
+
+    class OperandArray : public ObjectBase<OperandArray, WNNOperandArray> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        Operand Get(size_t index) const;
+        size_t Size() const;
+
+      private:
+        friend ObjectBase<OperandArray, WNNOperandArray>;
+        static void WebnnReference(WNNOperandArray handle);
+        static void WebnnRelease(WNNOperandArray handle);
+    };
+
+    class OperatorArray : public ObjectBase<OperatorArray, WNNOperatorArray> {
+      public:
+        using ObjectBase::ObjectBase;
+        using ObjectBase::operator=;
+
+        FusionOperator Get(size_t index) const;
+        void Set(FusionOperator const& wnnOperator) const;
+        size_t Size() const;
+
+      private:
+        friend ObjectBase<OperatorArray, WNNOperatorArray>;
+        static void WebnnReference(WNNOperatorArray handle);
+        static void WebnnRelease(WNNOperatorArray handle);
+    };
+
+
+    struct ChainedStruct {
+        ChainedStruct const * nextInChain = nullptr;
+        // SType sType = SType::Invalid;
+    };
+
+    struct ArrayBufferView {
+        void * buffer;
+        size_t byteLength;
+        size_t byteOffset = 0;
+    };
+
+    struct BatchNormOptions {
+        Operand scale;
+        Operand bias;
+        uint32_t axis = 1;
+        float epsilon = 1e-05;
+        FusionOperator activation;
+    };
+
+    struct ClampOptions {
+        float minValue = std::numeric_limits<float>::lowest();
+        float maxValue = std::numeric_limits<float>::max();
+    };
+
+    struct ContextOptions {
+        DevicePreference devicePreference = DevicePreference::Default;
+        PowerPreference powerPreference = PowerPreference::Default;
+    };
+
+    struct ConvTranspose2dOptions {
+        uint32_t paddingCount = 0;
+        int32_t const * padding = nullptr;
+        uint32_t stridesCount = 0;
+        int32_t const * strides = nullptr;
+        uint32_t dilationsCount = 0;
+        int32_t const * dilations = nullptr;
+        uint32_t outputPaddingCount = 0;
+        int32_t const * outputPadding = nullptr;
+        uint32_t outputSizesCount = 0;
+        int32_t const * outputSizes = nullptr;
+        AutoPad autoPad = AutoPad::Explicit;
+        int32_t groups = 1;
+        InputOperandLayout inputLayout = InputOperandLayout::Nchw;
+        ConvTranspose2dFilterOperandLayout filterLayout = ConvTranspose2dFilterOperandLayout::Iohw;
+        Operand bias;
+        FusionOperator activation;
+    };
+
+    struct Conv2dOptions {
+        uint32_t paddingCount = 0;
+        int32_t const * padding = nullptr;
+        uint32_t stridesCount = 0;
+        int32_t const * strides = nullptr;
+        uint32_t dilationsCount = 0;
+        int32_t const * dilations = nullptr;
+        AutoPad autoPad = AutoPad::Explicit;
+        int32_t groups = 1;
+        InputOperandLayout inputLayout = InputOperandLayout::Nchw;
+        Conv2dFilterOperandLayout filterLayout = Conv2dFilterOperandLayout::Oihw;
+        Operand bias;
+        FusionOperator activation;
+    };
+
+    struct GemmOptions {
+        Operand c;
+        float alpha = 1.0;
+        float beta = 1.0;
+        bool aTranspose = false;
+        bool bTranspose = false;
+    };
+
+    struct GpuBufferView {
+        void * buffer = nullptr;
+        uint32_t id = 0;
+        uint32_t generation = 0;
+        size_t size;
+        size_t offset = 0;
+    };
+
+    struct GpuDevice {
+        void * device = nullptr;
+        uint32_t id = 0;
+        uint32_t generation = 0;
+    };
+
+    struct GruOptions {
+        Operand bias;
+        Operand recurrentBias;
+        Operand initialHiddenState;
+        bool resetAfter = true;
+        bool returnSequence = false;
+        RecurrentNetworkDirection direction = RecurrentNetworkDirection::Forward;
+        RecurrentNetworkWeightLayout layout = RecurrentNetworkWeightLayout::Zrn;
+        OperatorArray activations;
+    };
+
+    struct InstanceDescriptor {
+    };
+
+    struct InstanceNormOptions {
+        Operand scale;
+        Operand bias;
+        float epsilon = 1e-05;
+        InputOperandLayout layout = InputOperandLayout::Nchw;
+    };
+
+    struct LeakyReluOptions {
+        float alpha = 0.01;
+    };
+
+    struct OperandDescriptor {
+        OperandType type;
+        int32_t const * dimensions;
+        uint32_t dimensionsCount = 0;
+    };
+
+    struct PadOptions {
+        PaddingMode mode = PaddingMode::Constant;
+        float value = 0;
+    };
+
+    struct Pool2dOptions {
+        uint32_t windowDimensionsCount = 0;
+        int32_t const * windowDimensions = nullptr;
+        uint32_t paddingCount = 0;
+        int32_t const * padding = nullptr;
+        uint32_t stridesCount = 0;
+        int32_t const * strides = nullptr;
+        uint32_t dilationsCount = 0;
+        int32_t const * dilations = nullptr;
+        AutoPad autoPad = AutoPad::Explicit;
+        InputOperandLayout layout = InputOperandLayout::Nchw;
+        RoundingType roundingType = RoundingType::Floor;
+        uint32_t outputSizesCount = 0;
+        int32_t const * outputSizes = nullptr;
+    };
+
+    struct ReduceOptions {
+        uint32_t axesCount = 0;
+        int32_t const * axes = nullptr;
+        bool keepDimensions = false;
+    };
+
+    struct Resample2dOptions {
+        InterpolationMode mode = InterpolationMode::NearestNeighbor;
+        uint32_t scalesCount = 0;
+        float const * scales = nullptr;
+        uint32_t sizesCount = 0;
+        int32_t const * sizes = nullptr;
+        uint32_t axesCount = 0;
+        int32_t const * axes = nullptr;
+    };
+
+    struct SliceOptions {
+        uint32_t axesCount = 0;
+        int32_t const * axes = nullptr;
+    };
+
+    struct SplitOptions {
+        int32_t axis = 0;
+    };
+
+    struct SqueezeOptions {
+        uint32_t axesCount = 0;
+        int32_t const * axes = nullptr;
+    };
+
+    struct TransposeOptions {
+        uint32_t permutationCount = 0;
+        int32_t const * permutation = nullptr;
+    };
+
+    struct Resource {
+        ArrayBufferView arrayBufferView;
+        GpuBufferView gpuBufferView;
+    };
+
+    struct Input {
+        Resource resource;
+        int32_t const * dimensions = nullptr;
+        uint32_t dimensionsCount = 0;
+    };
+
+
+    GraphBuilder CreateGraphBuilder(Context context);
+    NamedInputs CreateNamedInputs();
+    NamedOperands CreateNamedOperands();
+    NamedOutputs CreateNamedOutputs();
+    OperatorArray CreateOperatorArray();
+
+}  // namespace webnn
+
+#endif // WEBNN_CPP_H_
diff --git a/system/lib/webnn/webnn_cpp.cpp b/system/lib/webnn/webnn_cpp.cpp
new file mode 100644
index 000000000..736af0226
--- /dev/null
+++ b/system/lib/webnn/webnn_cpp.cpp
@@ -0,0 +1,1021 @@
+#include "webnn/webnn_cpp.h"
+
+namespace wnn {
+
+    // AutoPad
+
+    static_assert(sizeof(AutoPad) == sizeof(WNNAutoPad), "sizeof mismatch for AutoPad");
+    static_assert(alignof(AutoPad) == alignof(WNNAutoPad), "alignof mismatch for AutoPad");
+
+    static_assert(static_cast<uint32_t>(AutoPad::Explicit) == WNNAutoPad_Explicit, "value mismatch for AutoPad::Explicit");
+    static_assert(static_cast<uint32_t>(AutoPad::SameUpper) == WNNAutoPad_SameUpper, "value mismatch for AutoPad::SameUpper");
+    static_assert(static_cast<uint32_t>(AutoPad::SameLower) == WNNAutoPad_SameLower, "value mismatch for AutoPad::SameLower");
+
+    // BackendType
+
+    static_assert(sizeof(BackendType) == sizeof(WNNBackendType), "sizeof mismatch for BackendType");
+    static_assert(alignof(BackendType) == alignof(WNNBackendType), "alignof mismatch for BackendType");
+
+    static_assert(static_cast<uint32_t>(BackendType::Null) == WNNBackendType_Null, "value mismatch for BackendType::Null");
+    static_assert(static_cast<uint32_t>(BackendType::DirectML) == WNNBackendType_DirectML, "value mismatch for BackendType::DirectML");
+    static_assert(static_cast<uint32_t>(BackendType::DirectMLX) == WNNBackendType_DirectMLX, "value mismatch for BackendType::DirectMLX");
+    static_assert(static_cast<uint32_t>(BackendType::OpenVINO) == WNNBackendType_OpenVINO, "value mismatch for BackendType::OpenVINO");
+    static_assert(static_cast<uint32_t>(BackendType::OneDNN) == WNNBackendType_OneDNN, "value mismatch for BackendType::OneDNN");
+    static_assert(static_cast<uint32_t>(BackendType::MLAS) == WNNBackendType_MLAS, "value mismatch for BackendType::MLAS");
+    static_assert(static_cast<uint32_t>(BackendType::XNNPACK) == WNNBackendType_XNNPACK, "value mismatch for BackendType::XNNPACK");
+    static_assert(static_cast<uint32_t>(BackendType::NNAPI) == WNNBackendType_NNAPI, "value mismatch for BackendType::NNAPI");
+
+    // ConvTranspose2dFilterOperandLayout
+
+    static_assert(sizeof(ConvTranspose2dFilterOperandLayout) == sizeof(WNNConvTranspose2dFilterOperandLayout), "sizeof mismatch for ConvTranspose2dFilterOperandLayout");
+    static_assert(alignof(ConvTranspose2dFilterOperandLayout) == alignof(WNNConvTranspose2dFilterOperandLayout), "alignof mismatch for ConvTranspose2dFilterOperandLayout");
+
+    static_assert(static_cast<uint32_t>(ConvTranspose2dFilterOperandLayout::Iohw) == WNNConvTranspose2dFilterOperandLayout_Iohw, "value mismatch for ConvTranspose2dFilterOperandLayout::Iohw");
+    static_assert(static_cast<uint32_t>(ConvTranspose2dFilterOperandLayout::Hwoi) == WNNConvTranspose2dFilterOperandLayout_Hwoi, "value mismatch for ConvTranspose2dFilterOperandLayout::Hwoi");
+    static_assert(static_cast<uint32_t>(ConvTranspose2dFilterOperandLayout::Ohwi) == WNNConvTranspose2dFilterOperandLayout_Ohwi, "value mismatch for ConvTranspose2dFilterOperandLayout::Ohwi");
+
+    // Conv2dFilterOperandLayout
+
+    static_assert(sizeof(Conv2dFilterOperandLayout) == sizeof(WNNConv2dFilterOperandLayout), "sizeof mismatch for Conv2dFilterOperandLayout");
+    static_assert(alignof(Conv2dFilterOperandLayout) == alignof(WNNConv2dFilterOperandLayout), "alignof mismatch for Conv2dFilterOperandLayout");
+
+    static_assert(static_cast<uint32_t>(Conv2dFilterOperandLayout::Oihw) == WNNConv2dFilterOperandLayout_Oihw, "value mismatch for Conv2dFilterOperandLayout::Oihw");
+    static_assert(static_cast<uint32_t>(Conv2dFilterOperandLayout::Hwio) == WNNConv2dFilterOperandLayout_Hwio, "value mismatch for Conv2dFilterOperandLayout::Hwio");
+    static_assert(static_cast<uint32_t>(Conv2dFilterOperandLayout::Ohwi) == WNNConv2dFilterOperandLayout_Ohwi, "value mismatch for Conv2dFilterOperandLayout::Ohwi");
+    static_assert(static_cast<uint32_t>(Conv2dFilterOperandLayout::Ihwo) == WNNConv2dFilterOperandLayout_Ihwo, "value mismatch for Conv2dFilterOperandLayout::Ihwo");
+
+    // DevicePreference
+
+    static_assert(sizeof(DevicePreference) == sizeof(WNNDevicePreference), "sizeof mismatch for DevicePreference");
+    static_assert(alignof(DevicePreference) == alignof(WNNDevicePreference), "alignof mismatch for DevicePreference");
+
+    static_assert(static_cast<uint32_t>(DevicePreference::Default) == WNNDevicePreference_Default, "value mismatch for DevicePreference::Default");
+    static_assert(static_cast<uint32_t>(DevicePreference::Gpu) == WNNDevicePreference_Gpu, "value mismatch for DevicePreference::Gpu");
+    static_assert(static_cast<uint32_t>(DevicePreference::Cpu) == WNNDevicePreference_Cpu, "value mismatch for DevicePreference::Cpu");
+
+    // ErrorFilter
+
+    static_assert(sizeof(ErrorFilter) == sizeof(WNNErrorFilter), "sizeof mismatch for ErrorFilter");
+    static_assert(alignof(ErrorFilter) == alignof(WNNErrorFilter), "alignof mismatch for ErrorFilter");
+
+    static_assert(static_cast<uint32_t>(ErrorFilter::None) == WNNErrorFilter_None, "value mismatch for ErrorFilter::None");
+    static_assert(static_cast<uint32_t>(ErrorFilter::Validation) == WNNErrorFilter_Validation, "value mismatch for ErrorFilter::Validation");
+    static_assert(static_cast<uint32_t>(ErrorFilter::OutOfMemory) == WNNErrorFilter_OutOfMemory, "value mismatch for ErrorFilter::OutOfMemory");
+
+    // ErrorType
+
+    static_assert(sizeof(ErrorType) == sizeof(WNNErrorType), "sizeof mismatch for ErrorType");
+    static_assert(alignof(ErrorType) == alignof(WNNErrorType), "alignof mismatch for ErrorType");
+
+    static_assert(static_cast<uint32_t>(ErrorType::NoError) == WNNErrorType_NoError, "value mismatch for ErrorType::NoError");
+    static_assert(static_cast<uint32_t>(ErrorType::Validation) == WNNErrorType_Validation, "value mismatch for ErrorType::Validation");
+    static_assert(static_cast<uint32_t>(ErrorType::OutOfMemory) == WNNErrorType_OutOfMemory, "value mismatch for ErrorType::OutOfMemory");
+    static_assert(static_cast<uint32_t>(ErrorType::Unknown) == WNNErrorType_Unknown, "value mismatch for ErrorType::Unknown");
+    static_assert(static_cast<uint32_t>(ErrorType::DeviceLost) == WNNErrorType_DeviceLost, "value mismatch for ErrorType::DeviceLost");
+
+    // InputOperandLayout
+
+    static_assert(sizeof(InputOperandLayout) == sizeof(WNNInputOperandLayout), "sizeof mismatch for InputOperandLayout");
+    static_assert(alignof(InputOperandLayout) == alignof(WNNInputOperandLayout), "alignof mismatch for InputOperandLayout");
+
+    static_assert(static_cast<uint32_t>(InputOperandLayout::Nchw) == WNNInputOperandLayout_Nchw, "value mismatch for InputOperandLayout::Nchw");
+    static_assert(static_cast<uint32_t>(InputOperandLayout::Nhwc) == WNNInputOperandLayout_Nhwc, "value mismatch for InputOperandLayout::Nhwc");
+
+    // InterpolationMode
+
+    static_assert(sizeof(InterpolationMode) == sizeof(WNNInterpolationMode), "sizeof mismatch for InterpolationMode");
+    static_assert(alignof(InterpolationMode) == alignof(WNNInterpolationMode), "alignof mismatch for InterpolationMode");
+
+    static_assert(static_cast<uint32_t>(InterpolationMode::NearestNeighbor) == WNNInterpolationMode_NearestNeighbor, "value mismatch for InterpolationMode::NearestNeighbor");
+    static_assert(static_cast<uint32_t>(InterpolationMode::Linear) == WNNInterpolationMode_Linear, "value mismatch for InterpolationMode::Linear");
+
+    // OperandType
+
+    static_assert(sizeof(OperandType) == sizeof(WNNOperandType), "sizeof mismatch for OperandType");
+    static_assert(alignof(OperandType) == alignof(WNNOperandType), "alignof mismatch for OperandType");
+
+    static_assert(static_cast<uint32_t>(OperandType::Float32) == WNNOperandType_Float32, "value mismatch for OperandType::Float32");
+    static_assert(static_cast<uint32_t>(OperandType::Float16) == WNNOperandType_Float16, "value mismatch for OperandType::Float16");
+    static_assert(static_cast<uint32_t>(OperandType::Int32) == WNNOperandType_Int32, "value mismatch for OperandType::Int32");
+    static_assert(static_cast<uint32_t>(OperandType::Uint32) == WNNOperandType_Uint32, "value mismatch for OperandType::Uint32");
+    static_assert(static_cast<uint32_t>(OperandType::Int8) == WNNOperandType_Int8, "value mismatch for OperandType::Int8");
+    static_assert(static_cast<uint32_t>(OperandType::Uint8) == WNNOperandType_Uint8, "value mismatch for OperandType::Uint8");
+
+    // PaddingMode
+
+    static_assert(sizeof(PaddingMode) == sizeof(WNNPaddingMode), "sizeof mismatch for PaddingMode");
+    static_assert(alignof(PaddingMode) == alignof(WNNPaddingMode), "alignof mismatch for PaddingMode");
+
+    static_assert(static_cast<uint32_t>(PaddingMode::Constant) == WNNPaddingMode_Constant, "value mismatch for PaddingMode::Constant");
+    static_assert(static_cast<uint32_t>(PaddingMode::Edge) == WNNPaddingMode_Edge, "value mismatch for PaddingMode::Edge");
+    static_assert(static_cast<uint32_t>(PaddingMode::Reflection) == WNNPaddingMode_Reflection, "value mismatch for PaddingMode::Reflection");
+    static_assert(static_cast<uint32_t>(PaddingMode::Symmetric) == WNNPaddingMode_Symmetric, "value mismatch for PaddingMode::Symmetric");
+
+    // PowerPreference
+
+    static_assert(sizeof(PowerPreference) == sizeof(WNNPowerPreference), "sizeof mismatch for PowerPreference");
+    static_assert(alignof(PowerPreference) == alignof(WNNPowerPreference), "alignof mismatch for PowerPreference");
+
+    static_assert(static_cast<uint32_t>(PowerPreference::Default) == WNNPowerPreference_Default, "value mismatch for PowerPreference::Default");
+    static_assert(static_cast<uint32_t>(PowerPreference::High_performance) == WNNPowerPreference_High_performance, "value mismatch for PowerPreference::High_performance");
+    static_assert(static_cast<uint32_t>(PowerPreference::Low_power) == WNNPowerPreference_Low_power, "value mismatch for PowerPreference::Low_power");
+
+    // RecurrentNetworkDirection
+
+    static_assert(sizeof(RecurrentNetworkDirection) == sizeof(WNNRecurrentNetworkDirection), "sizeof mismatch for RecurrentNetworkDirection");
+    static_assert(alignof(RecurrentNetworkDirection) == alignof(WNNRecurrentNetworkDirection), "alignof mismatch for RecurrentNetworkDirection");
+
+    static_assert(static_cast<uint32_t>(RecurrentNetworkDirection::Forward) == WNNRecurrentNetworkDirection_Forward, "value mismatch for RecurrentNetworkDirection::Forward");
+    static_assert(static_cast<uint32_t>(RecurrentNetworkDirection::Backward) == WNNRecurrentNetworkDirection_Backward, "value mismatch for RecurrentNetworkDirection::Backward");
+    static_assert(static_cast<uint32_t>(RecurrentNetworkDirection::Both) == WNNRecurrentNetworkDirection_Both, "value mismatch for RecurrentNetworkDirection::Both");
+
+    // RecurrentNetworkWeightLayout
+
+    static_assert(sizeof(RecurrentNetworkWeightLayout) == sizeof(WNNRecurrentNetworkWeightLayout), "sizeof mismatch for RecurrentNetworkWeightLayout");
+    static_assert(alignof(RecurrentNetworkWeightLayout) == alignof(WNNRecurrentNetworkWeightLayout), "alignof mismatch for RecurrentNetworkWeightLayout");
+
+    static_assert(static_cast<uint32_t>(RecurrentNetworkWeightLayout::Zrn) == WNNRecurrentNetworkWeightLayout_Zrn, "value mismatch for RecurrentNetworkWeightLayout::Zrn");
+    static_assert(static_cast<uint32_t>(RecurrentNetworkWeightLayout::Rzn) == WNNRecurrentNetworkWeightLayout_Rzn, "value mismatch for RecurrentNetworkWeightLayout::Rzn");
+
+    // RoundingType
+
+    static_assert(sizeof(RoundingType) == sizeof(WNNRoundingType), "sizeof mismatch for RoundingType");
+    static_assert(alignof(RoundingType) == alignof(WNNRoundingType), "alignof mismatch for RoundingType");
+
+    static_assert(static_cast<uint32_t>(RoundingType::Floor) == WNNRoundingType_Floor, "value mismatch for RoundingType::Floor");
+    static_assert(static_cast<uint32_t>(RoundingType::Ceil) == WNNRoundingType_Ceil, "value mismatch for RoundingType::Ceil");
+
+    // ChainedStruct
+
+
+    // ArrayBufferView
+
+    static_assert(sizeof(ArrayBufferView) == sizeof(WNNArrayBufferView), "sizeof mismatch for ArrayBufferView");
+    static_assert(alignof(ArrayBufferView) == alignof(WNNArrayBufferView), "alignof mismatch for ArrayBufferView");
+
+    static_assert(offsetof(ArrayBufferView, buffer) == offsetof(WNNArrayBufferView, buffer),
+            "offsetof mismatch for ArrayBufferView::buffer");
+    static_assert(offsetof(ArrayBufferView, byteLength) == offsetof(WNNArrayBufferView, byteLength),
+            "offsetof mismatch for ArrayBufferView::byteLength");
+    static_assert(offsetof(ArrayBufferView, byteOffset) == offsetof(WNNArrayBufferView, byteOffset),
+            "offsetof mismatch for ArrayBufferView::byteOffset");
+
+    // BatchNormOptions
+
+    static_assert(sizeof(BatchNormOptions) == sizeof(WNNBatchNormOptions), "sizeof mismatch for BatchNormOptions");
+    static_assert(alignof(BatchNormOptions) == alignof(WNNBatchNormOptions), "alignof mismatch for BatchNormOptions");
+
+    static_assert(offsetof(BatchNormOptions, scale) == offsetof(WNNBatchNormOptions, scale),
+            "offsetof mismatch for BatchNormOptions::scale");
+    static_assert(offsetof(BatchNormOptions, bias) == offsetof(WNNBatchNormOptions, bias),
+            "offsetof mismatch for BatchNormOptions::bias");
+    static_assert(offsetof(BatchNormOptions, axis) == offsetof(WNNBatchNormOptions, axis),
+            "offsetof mismatch for BatchNormOptions::axis");
+    static_assert(offsetof(BatchNormOptions, epsilon) == offsetof(WNNBatchNormOptions, epsilon),
+            "offsetof mismatch for BatchNormOptions::epsilon");
+    static_assert(offsetof(BatchNormOptions, activation) == offsetof(WNNBatchNormOptions, activation),
+            "offsetof mismatch for BatchNormOptions::activation");
+
+    // ClampOptions
+
+    static_assert(sizeof(ClampOptions) == sizeof(WNNClampOptions), "sizeof mismatch for ClampOptions");
+    static_assert(alignof(ClampOptions) == alignof(WNNClampOptions), "alignof mismatch for ClampOptions");
+
+    static_assert(offsetof(ClampOptions, minValue) == offsetof(WNNClampOptions, minValue),
+            "offsetof mismatch for ClampOptions::minValue");
+    static_assert(offsetof(ClampOptions, maxValue) == offsetof(WNNClampOptions, maxValue),
+            "offsetof mismatch for ClampOptions::maxValue");
+
+    // ContextOptions
+
+    static_assert(sizeof(ContextOptions) == sizeof(WNNContextOptions), "sizeof mismatch for ContextOptions");
+    static_assert(alignof(ContextOptions) == alignof(WNNContextOptions), "alignof mismatch for ContextOptions");
+
+    static_assert(offsetof(ContextOptions, devicePreference) == offsetof(WNNContextOptions, devicePreference),
+            "offsetof mismatch for ContextOptions::devicePreference");
+    static_assert(offsetof(ContextOptions, powerPreference) == offsetof(WNNContextOptions, powerPreference),
+            "offsetof mismatch for ContextOptions::powerPreference");
+
+    // ConvTranspose2dOptions
+
+    static_assert(sizeof(ConvTranspose2dOptions) == sizeof(WNNConvTranspose2dOptions), "sizeof mismatch for ConvTranspose2dOptions");
+    static_assert(alignof(ConvTranspose2dOptions) == alignof(WNNConvTranspose2dOptions), "alignof mismatch for ConvTranspose2dOptions");
+
+    static_assert(offsetof(ConvTranspose2dOptions, paddingCount) == offsetof(WNNConvTranspose2dOptions, paddingCount),
+            "offsetof mismatch for ConvTranspose2dOptions::paddingCount");
+    static_assert(offsetof(ConvTranspose2dOptions, padding) == offsetof(WNNConvTranspose2dOptions, padding),
+            "offsetof mismatch for ConvTranspose2dOptions::padding");
+    static_assert(offsetof(ConvTranspose2dOptions, stridesCount) == offsetof(WNNConvTranspose2dOptions, stridesCount),
+            "offsetof mismatch for ConvTranspose2dOptions::stridesCount");
+    static_assert(offsetof(ConvTranspose2dOptions, strides) == offsetof(WNNConvTranspose2dOptions, strides),
+            "offsetof mismatch for ConvTranspose2dOptions::strides");
+    static_assert(offsetof(ConvTranspose2dOptions, dilationsCount) == offsetof(WNNConvTranspose2dOptions, dilationsCount),
+            "offsetof mismatch for ConvTranspose2dOptions::dilationsCount");
+    static_assert(offsetof(ConvTranspose2dOptions, dilations) == offsetof(WNNConvTranspose2dOptions, dilations),
+            "offsetof mismatch for ConvTranspose2dOptions::dilations");
+    static_assert(offsetof(ConvTranspose2dOptions, outputPaddingCount) == offsetof(WNNConvTranspose2dOptions, outputPaddingCount),
+            "offsetof mismatch for ConvTranspose2dOptions::outputPaddingCount");
+    static_assert(offsetof(ConvTranspose2dOptions, outputPadding) == offsetof(WNNConvTranspose2dOptions, outputPadding),
+            "offsetof mismatch for ConvTranspose2dOptions::outputPadding");
+    static_assert(offsetof(ConvTranspose2dOptions, outputSizesCount) == offsetof(WNNConvTranspose2dOptions, outputSizesCount),
+            "offsetof mismatch for ConvTranspose2dOptions::outputSizesCount");
+    static_assert(offsetof(ConvTranspose2dOptions, outputSizes) == offsetof(WNNConvTranspose2dOptions, outputSizes),
+            "offsetof mismatch for ConvTranspose2dOptions::outputSizes");
+    static_assert(offsetof(ConvTranspose2dOptions, autoPad) == offsetof(WNNConvTranspose2dOptions, autoPad),
+            "offsetof mismatch for ConvTranspose2dOptions::autoPad");
+    static_assert(offsetof(ConvTranspose2dOptions, groups) == offsetof(WNNConvTranspose2dOptions, groups),
+            "offsetof mismatch for ConvTranspose2dOptions::groups");
+    static_assert(offsetof(ConvTranspose2dOptions, inputLayout) == offsetof(WNNConvTranspose2dOptions, inputLayout),
+            "offsetof mismatch for ConvTranspose2dOptions::inputLayout");
+    static_assert(offsetof(ConvTranspose2dOptions, filterLayout) == offsetof(WNNConvTranspose2dOptions, filterLayout),
+            "offsetof mismatch for ConvTranspose2dOptions::filterLayout");
+    static_assert(offsetof(ConvTranspose2dOptions, bias) == offsetof(WNNConvTranspose2dOptions, bias),
+            "offsetof mismatch for ConvTranspose2dOptions::bias");
+    static_assert(offsetof(ConvTranspose2dOptions, activation) == offsetof(WNNConvTranspose2dOptions, activation),
+            "offsetof mismatch for ConvTranspose2dOptions::activation");
+
+    // Conv2dOptions
+
+    static_assert(sizeof(Conv2dOptions) == sizeof(WNNConv2dOptions), "sizeof mismatch for Conv2dOptions");
+    static_assert(alignof(Conv2dOptions) == alignof(WNNConv2dOptions), "alignof mismatch for Conv2dOptions");
+
+    static_assert(offsetof(Conv2dOptions, paddingCount) == offsetof(WNNConv2dOptions, paddingCount),
+            "offsetof mismatch for Conv2dOptions::paddingCount");
+    static_assert(offsetof(Conv2dOptions, padding) == offsetof(WNNConv2dOptions, padding),
+            "offsetof mismatch for Conv2dOptions::padding");
+    static_assert(offsetof(Conv2dOptions, stridesCount) == offsetof(WNNConv2dOptions, stridesCount),
+            "offsetof mismatch for Conv2dOptions::stridesCount");
+    static_assert(offsetof(Conv2dOptions, strides) == offsetof(WNNConv2dOptions, strides),
+            "offsetof mismatch for Conv2dOptions::strides");
+    static_assert(offsetof(Conv2dOptions, dilationsCount) == offsetof(WNNConv2dOptions, dilationsCount),
+            "offsetof mismatch for Conv2dOptions::dilationsCount");
+    static_assert(offsetof(Conv2dOptions, dilations) == offsetof(WNNConv2dOptions, dilations),
+            "offsetof mismatch for Conv2dOptions::dilations");
+    static_assert(offsetof(Conv2dOptions, autoPad) == offsetof(WNNConv2dOptions, autoPad),
+            "offsetof mismatch for Conv2dOptions::autoPad");
+    static_assert(offsetof(Conv2dOptions, groups) == offsetof(WNNConv2dOptions, groups),
+            "offsetof mismatch for Conv2dOptions::groups");
+    static_assert(offsetof(Conv2dOptions, inputLayout) == offsetof(WNNConv2dOptions, inputLayout),
+            "offsetof mismatch for Conv2dOptions::inputLayout");
+    static_assert(offsetof(Conv2dOptions, filterLayout) == offsetof(WNNConv2dOptions, filterLayout),
+            "offsetof mismatch for Conv2dOptions::filterLayout");
+    static_assert(offsetof(Conv2dOptions, bias) == offsetof(WNNConv2dOptions, bias),
+            "offsetof mismatch for Conv2dOptions::bias");
+    static_assert(offsetof(Conv2dOptions, activation) == offsetof(WNNConv2dOptions, activation),
+            "offsetof mismatch for Conv2dOptions::activation");
+
+    // GemmOptions
+
+    static_assert(sizeof(GemmOptions) == sizeof(WNNGemmOptions), "sizeof mismatch for GemmOptions");
+    static_assert(alignof(GemmOptions) == alignof(WNNGemmOptions), "alignof mismatch for GemmOptions");
+
+    static_assert(offsetof(GemmOptions, c) == offsetof(WNNGemmOptions, c),
+            "offsetof mismatch for GemmOptions::c");
+    static_assert(offsetof(GemmOptions, alpha) == offsetof(WNNGemmOptions, alpha),
+            "offsetof mismatch for GemmOptions::alpha");
+    static_assert(offsetof(GemmOptions, beta) == offsetof(WNNGemmOptions, beta),
+            "offsetof mismatch for GemmOptions::beta");
+    static_assert(offsetof(GemmOptions, aTranspose) == offsetof(WNNGemmOptions, aTranspose),
+            "offsetof mismatch for GemmOptions::aTranspose");
+    static_assert(offsetof(GemmOptions, bTranspose) == offsetof(WNNGemmOptions, bTranspose),
+            "offsetof mismatch for GemmOptions::bTranspose");
+
+    // GpuBufferView
+
+    static_assert(sizeof(GpuBufferView) == sizeof(WNNGpuBufferView), "sizeof mismatch for GpuBufferView");
+    static_assert(alignof(GpuBufferView) == alignof(WNNGpuBufferView), "alignof mismatch for GpuBufferView");
+
+    static_assert(offsetof(GpuBufferView, buffer) == offsetof(WNNGpuBufferView, buffer),
+            "offsetof mismatch for GpuBufferView::buffer");
+    static_assert(offsetof(GpuBufferView, id) == offsetof(WNNGpuBufferView, id),
+            "offsetof mismatch for GpuBufferView::id");
+    static_assert(offsetof(GpuBufferView, generation) == offsetof(WNNGpuBufferView, generation),
+            "offsetof mismatch for GpuBufferView::generation");
+    static_assert(offsetof(GpuBufferView, size) == offsetof(WNNGpuBufferView, size),
+            "offsetof mismatch for GpuBufferView::size");
+    static_assert(offsetof(GpuBufferView, offset) == offsetof(WNNGpuBufferView, offset),
+            "offsetof mismatch for GpuBufferView::offset");
+
+    // GpuDevice
+
+    static_assert(sizeof(GpuDevice) == sizeof(WNNGpuDevice), "sizeof mismatch for GpuDevice");
+    static_assert(alignof(GpuDevice) == alignof(WNNGpuDevice), "alignof mismatch for GpuDevice");
+
+    static_assert(offsetof(GpuDevice, device) == offsetof(WNNGpuDevice, device),
+            "offsetof mismatch for GpuDevice::device");
+    static_assert(offsetof(GpuDevice, id) == offsetof(WNNGpuDevice, id),
+            "offsetof mismatch for GpuDevice::id");
+    static_assert(offsetof(GpuDevice, generation) == offsetof(WNNGpuDevice, generation),
+            "offsetof mismatch for GpuDevice::generation");
+
+    // GruOptions
+
+    static_assert(sizeof(GruOptions) == sizeof(WNNGruOptions), "sizeof mismatch for GruOptions");
+    static_assert(alignof(GruOptions) == alignof(WNNGruOptions), "alignof mismatch for GruOptions");
+
+    static_assert(offsetof(GruOptions, bias) == offsetof(WNNGruOptions, bias),
+            "offsetof mismatch for GruOptions::bias");
+    static_assert(offsetof(GruOptions, recurrentBias) == offsetof(WNNGruOptions, recurrentBias),
+            "offsetof mismatch for GruOptions::recurrentBias");
+    static_assert(offsetof(GruOptions, initialHiddenState) == offsetof(WNNGruOptions, initialHiddenState),
+            "offsetof mismatch for GruOptions::initialHiddenState");
+    static_assert(offsetof(GruOptions, resetAfter) == offsetof(WNNGruOptions, resetAfter),
+            "offsetof mismatch for GruOptions::resetAfter");
+    static_assert(offsetof(GruOptions, returnSequence) == offsetof(WNNGruOptions, returnSequence),
+            "offsetof mismatch for GruOptions::returnSequence");
+    static_assert(offsetof(GruOptions, direction) == offsetof(WNNGruOptions, direction),
+            "offsetof mismatch for GruOptions::direction");
+    static_assert(offsetof(GruOptions, layout) == offsetof(WNNGruOptions, layout),
+            "offsetof mismatch for GruOptions::layout");
+    static_assert(offsetof(GruOptions, activations) == offsetof(WNNGruOptions, activations),
+            "offsetof mismatch for GruOptions::activations");
+
+    // InstanceDescriptor
+
+    static_assert(sizeof(InstanceDescriptor) == sizeof(WNNInstanceDescriptor), "sizeof mismatch for InstanceDescriptor");
+    static_assert(alignof(InstanceDescriptor) == alignof(WNNInstanceDescriptor), "alignof mismatch for InstanceDescriptor");
+
+
+    // InstanceNormOptions
+
+    static_assert(sizeof(InstanceNormOptions) == sizeof(WNNInstanceNormOptions), "sizeof mismatch for InstanceNormOptions");
+    static_assert(alignof(InstanceNormOptions) == alignof(WNNInstanceNormOptions), "alignof mismatch for InstanceNormOptions");
+
+    static_assert(offsetof(InstanceNormOptions, scale) == offsetof(WNNInstanceNormOptions, scale),
+            "offsetof mismatch for InstanceNormOptions::scale");
+    static_assert(offsetof(InstanceNormOptions, bias) == offsetof(WNNInstanceNormOptions, bias),
+            "offsetof mismatch for InstanceNormOptions::bias");
+    static_assert(offsetof(InstanceNormOptions, epsilon) == offsetof(WNNInstanceNormOptions, epsilon),
+            "offsetof mismatch for InstanceNormOptions::epsilon");
+    static_assert(offsetof(InstanceNormOptions, layout) == offsetof(WNNInstanceNormOptions, layout),
+            "offsetof mismatch for InstanceNormOptions::layout");
+
+    // LeakyReluOptions
+
+    static_assert(sizeof(LeakyReluOptions) == sizeof(WNNLeakyReluOptions), "sizeof mismatch for LeakyReluOptions");
+    static_assert(alignof(LeakyReluOptions) == alignof(WNNLeakyReluOptions), "alignof mismatch for LeakyReluOptions");
+
+    static_assert(offsetof(LeakyReluOptions, alpha) == offsetof(WNNLeakyReluOptions, alpha),
+            "offsetof mismatch for LeakyReluOptions::alpha");
+
+    // OperandDescriptor
+
+    static_assert(sizeof(OperandDescriptor) == sizeof(WNNOperandDescriptor), "sizeof mismatch for OperandDescriptor");
+    static_assert(alignof(OperandDescriptor) == alignof(WNNOperandDescriptor), "alignof mismatch for OperandDescriptor");
+
+    static_assert(offsetof(OperandDescriptor, type) == offsetof(WNNOperandDescriptor, type),
+            "offsetof mismatch for OperandDescriptor::type");
+    static_assert(offsetof(OperandDescriptor, dimensions) == offsetof(WNNOperandDescriptor, dimensions),
+            "offsetof mismatch for OperandDescriptor::dimensions");
+    static_assert(offsetof(OperandDescriptor, dimensionsCount) == offsetof(WNNOperandDescriptor, dimensionsCount),
+            "offsetof mismatch for OperandDescriptor::dimensionsCount");
+
+    // PadOptions
+
+    static_assert(sizeof(PadOptions) == sizeof(WNNPadOptions), "sizeof mismatch for PadOptions");
+    static_assert(alignof(PadOptions) == alignof(WNNPadOptions), "alignof mismatch for PadOptions");
+
+    static_assert(offsetof(PadOptions, mode) == offsetof(WNNPadOptions, mode),
+            "offsetof mismatch for PadOptions::mode");
+    static_assert(offsetof(PadOptions, value) == offsetof(WNNPadOptions, value),
+            "offsetof mismatch for PadOptions::value");
+
+    // Pool2dOptions
+
+    static_assert(sizeof(Pool2dOptions) == sizeof(WNNPool2dOptions), "sizeof mismatch for Pool2dOptions");
+    static_assert(alignof(Pool2dOptions) == alignof(WNNPool2dOptions), "alignof mismatch for Pool2dOptions");
+
+    static_assert(offsetof(Pool2dOptions, windowDimensionsCount) == offsetof(WNNPool2dOptions, windowDimensionsCount),
+            "offsetof mismatch for Pool2dOptions::windowDimensionsCount");
+    static_assert(offsetof(Pool2dOptions, windowDimensions) == offsetof(WNNPool2dOptions, windowDimensions),
+            "offsetof mismatch for Pool2dOptions::windowDimensions");
+    static_assert(offsetof(Pool2dOptions, paddingCount) == offsetof(WNNPool2dOptions, paddingCount),
+            "offsetof mismatch for Pool2dOptions::paddingCount");
+    static_assert(offsetof(Pool2dOptions, padding) == offsetof(WNNPool2dOptions, padding),
+            "offsetof mismatch for Pool2dOptions::padding");
+    static_assert(offsetof(Pool2dOptions, stridesCount) == offsetof(WNNPool2dOptions, stridesCount),
+            "offsetof mismatch for Pool2dOptions::stridesCount");
+    static_assert(offsetof(Pool2dOptions, strides) == offsetof(WNNPool2dOptions, strides),
+            "offsetof mismatch for Pool2dOptions::strides");
+    static_assert(offsetof(Pool2dOptions, dilationsCount) == offsetof(WNNPool2dOptions, dilationsCount),
+            "offsetof mismatch for Pool2dOptions::dilationsCount");
+    static_assert(offsetof(Pool2dOptions, dilations) == offsetof(WNNPool2dOptions, dilations),
+            "offsetof mismatch for Pool2dOptions::dilations");
+    static_assert(offsetof(Pool2dOptions, autoPad) == offsetof(WNNPool2dOptions, autoPad),
+            "offsetof mismatch for Pool2dOptions::autoPad");
+    static_assert(offsetof(Pool2dOptions, layout) == offsetof(WNNPool2dOptions, layout),
+            "offsetof mismatch for Pool2dOptions::layout");
+    static_assert(offsetof(Pool2dOptions, roundingType) == offsetof(WNNPool2dOptions, roundingType),
+            "offsetof mismatch for Pool2dOptions::roundingType");
+    static_assert(offsetof(Pool2dOptions, outputSizesCount) == offsetof(WNNPool2dOptions, outputSizesCount),
+            "offsetof mismatch for Pool2dOptions::outputSizesCount");
+    static_assert(offsetof(Pool2dOptions, outputSizes) == offsetof(WNNPool2dOptions, outputSizes),
+            "offsetof mismatch for Pool2dOptions::outputSizes");
+
+    // ReduceOptions
+
+    static_assert(sizeof(ReduceOptions) == sizeof(WNNReduceOptions), "sizeof mismatch for ReduceOptions");
+    static_assert(alignof(ReduceOptions) == alignof(WNNReduceOptions), "alignof mismatch for ReduceOptions");
+
+    static_assert(offsetof(ReduceOptions, axesCount) == offsetof(WNNReduceOptions, axesCount),
+            "offsetof mismatch for ReduceOptions::axesCount");
+    static_assert(offsetof(ReduceOptions, axes) == offsetof(WNNReduceOptions, axes),
+            "offsetof mismatch for ReduceOptions::axes");
+    static_assert(offsetof(ReduceOptions, keepDimensions) == offsetof(WNNReduceOptions, keepDimensions),
+            "offsetof mismatch for ReduceOptions::keepDimensions");
+
+    // Resample2dOptions
+
+    static_assert(sizeof(Resample2dOptions) == sizeof(WNNResample2dOptions), "sizeof mismatch for Resample2dOptions");
+    static_assert(alignof(Resample2dOptions) == alignof(WNNResample2dOptions), "alignof mismatch for Resample2dOptions");
+
+    static_assert(offsetof(Resample2dOptions, mode) == offsetof(WNNResample2dOptions, mode),
+            "offsetof mismatch for Resample2dOptions::mode");
+    static_assert(offsetof(Resample2dOptions, scalesCount) == offsetof(WNNResample2dOptions, scalesCount),
+            "offsetof mismatch for Resample2dOptions::scalesCount");
+    static_assert(offsetof(Resample2dOptions, scales) == offsetof(WNNResample2dOptions, scales),
+            "offsetof mismatch for Resample2dOptions::scales");
+    static_assert(offsetof(Resample2dOptions, sizesCount) == offsetof(WNNResample2dOptions, sizesCount),
+            "offsetof mismatch for Resample2dOptions::sizesCount");
+    static_assert(offsetof(Resample2dOptions, sizes) == offsetof(WNNResample2dOptions, sizes),
+            "offsetof mismatch for Resample2dOptions::sizes");
+    static_assert(offsetof(Resample2dOptions, axesCount) == offsetof(WNNResample2dOptions, axesCount),
+            "offsetof mismatch for Resample2dOptions::axesCount");
+    static_assert(offsetof(Resample2dOptions, axes) == offsetof(WNNResample2dOptions, axes),
+            "offsetof mismatch for Resample2dOptions::axes");
+
+    // SliceOptions
+
+    static_assert(sizeof(SliceOptions) == sizeof(WNNSliceOptions), "sizeof mismatch for SliceOptions");
+    static_assert(alignof(SliceOptions) == alignof(WNNSliceOptions), "alignof mismatch for SliceOptions");
+
+    static_assert(offsetof(SliceOptions, axesCount) == offsetof(WNNSliceOptions, axesCount),
+            "offsetof mismatch for SliceOptions::axesCount");
+    static_assert(offsetof(SliceOptions, axes) == offsetof(WNNSliceOptions, axes),
+            "offsetof mismatch for SliceOptions::axes");
+
+    // SplitOptions
+
+    static_assert(sizeof(SplitOptions) == sizeof(WNNSplitOptions), "sizeof mismatch for SplitOptions");
+    static_assert(alignof(SplitOptions) == alignof(WNNSplitOptions), "alignof mismatch for SplitOptions");
+
+    static_assert(offsetof(SplitOptions, axis) == offsetof(WNNSplitOptions, axis),
+            "offsetof mismatch for SplitOptions::axis");
+
+    // SqueezeOptions
+
+    static_assert(sizeof(SqueezeOptions) == sizeof(WNNSqueezeOptions), "sizeof mismatch for SqueezeOptions");
+    static_assert(alignof(SqueezeOptions) == alignof(WNNSqueezeOptions), "alignof mismatch for SqueezeOptions");
+
+    static_assert(offsetof(SqueezeOptions, axesCount) == offsetof(WNNSqueezeOptions, axesCount),
+            "offsetof mismatch for SqueezeOptions::axesCount");
+    static_assert(offsetof(SqueezeOptions, axes) == offsetof(WNNSqueezeOptions, axes),
+            "offsetof mismatch for SqueezeOptions::axes");
+
+    // TransposeOptions
+
+    static_assert(sizeof(TransposeOptions) == sizeof(WNNTransposeOptions), "sizeof mismatch for TransposeOptions");
+    static_assert(alignof(TransposeOptions) == alignof(WNNTransposeOptions), "alignof mismatch for TransposeOptions");
+
+    static_assert(offsetof(TransposeOptions, permutationCount) == offsetof(WNNTransposeOptions, permutationCount),
+            "offsetof mismatch for TransposeOptions::permutationCount");
+    static_assert(offsetof(TransposeOptions, permutation) == offsetof(WNNTransposeOptions, permutation),
+            "offsetof mismatch for TransposeOptions::permutation");
+
+    // Resource
+
+    static_assert(sizeof(Resource) == sizeof(WNNResource), "sizeof mismatch for Resource");
+    static_assert(alignof(Resource) == alignof(WNNResource), "alignof mismatch for Resource");
+
+    static_assert(offsetof(Resource, arrayBufferView) == offsetof(WNNResource, arrayBufferView),
+            "offsetof mismatch for Resource::arrayBufferView");
+    static_assert(offsetof(Resource, gpuBufferView) == offsetof(WNNResource, gpuBufferView),
+            "offsetof mismatch for Resource::gpuBufferView");
+
+    // Input
+
+    static_assert(sizeof(Input) == sizeof(WNNInput), "sizeof mismatch for Input");
+    static_assert(alignof(Input) == alignof(WNNInput), "alignof mismatch for Input");
+
+    static_assert(offsetof(Input, resource) == offsetof(WNNInput, resource),
+            "offsetof mismatch for Input::resource");
+    static_assert(offsetof(Input, dimensions) == offsetof(WNNInput, dimensions),
+            "offsetof mismatch for Input::dimensions");
+    static_assert(offsetof(Input, dimensionsCount) == offsetof(WNNInput, dimensionsCount),
+            "offsetof mismatch for Input::dimensionsCount");
+
+    // Context
+
+    static_assert(sizeof(Context) == sizeof(WNNContext), "sizeof mismatch for Context");
+    static_assert(alignof(Context) == alignof(WNNContext), "alignof mismatch for Context");
+
+    void Context::Compute(Graph const& graph, NamedInputs const& inputs, NamedOutputs const& outputs, ComputeAsyncCallback callback, void * userdata) const {
+        wnnContextCompute(GetHandle(), graph.GetHandle(), inputs.GetHandle(), outputs.GetHandle(), callback, reinterpret_cast<void * >(userdata));
+    }
+    void Context::ComputeSync(Graph const& graph, NamedInputs const& inputs, NamedOutputs const& outputs) const {
+        wnnContextComputeSync(GetHandle(), graph.GetHandle(), inputs.GetHandle(), outputs.GetHandle());
+    }
+    void Context::InjectError(ErrorType type, char const * message) const {
+        wnnContextInjectError(GetHandle(), static_cast<WNNErrorType>(type), reinterpret_cast<char const * >(message));
+    }
+    bool Context::PopErrorScope(ErrorCallback callback, void * userdata) const {
+        auto result = wnnContextPopErrorScope(GetHandle(), callback, reinterpret_cast<void * >(userdata));
+        return result;
+    }
+    void Context::PushErrorScope(ErrorFilter filter) const {
+        wnnContextPushErrorScope(GetHandle(), static_cast<WNNErrorFilter>(filter));
+    }
+    void Context::SetUncapturedErrorCallback(ErrorCallback callback, void * userdata) const {
+        wnnContextSetUncapturedErrorCallback(GetHandle(), callback, reinterpret_cast<void * >(userdata));
+    }
+    void Context::WebnnReference(WNNContext handle) {
+        if (handle != nullptr) {
+            wnnContextReference(handle);
+        }
+    }
+    void Context::WebnnRelease(WNNContext handle) {
+        if (handle != nullptr) {
+            wnnContextRelease(handle);
+        }
+    }
+
+    // FusionOperator
+
+    static_assert(sizeof(FusionOperator) == sizeof(WNNFusionOperator), "sizeof mismatch for FusionOperator");
+    static_assert(alignof(FusionOperator) == alignof(WNNFusionOperator), "alignof mismatch for FusionOperator");
+
+    void FusionOperator::WebnnReference(WNNFusionOperator handle) {
+        if (handle != nullptr) {
+            wnnFusionOperatorReference(handle);
+        }
+    }
+    void FusionOperator::WebnnRelease(WNNFusionOperator handle) {
+        if (handle != nullptr) {
+            wnnFusionOperatorRelease(handle);
+        }
+    }
+
+    // Graph
+
+    static_assert(sizeof(Graph) == sizeof(WNNGraph), "sizeof mismatch for Graph");
+    static_assert(alignof(Graph) == alignof(WNNGraph), "alignof mismatch for Graph");
+
+    void Graph::WebnnReference(WNNGraph handle) {
+        if (handle != nullptr) {
+            wnnGraphReference(handle);
+        }
+    }
+    void Graph::WebnnRelease(WNNGraph handle) {
+        if (handle != nullptr) {
+            wnnGraphRelease(handle);
+        }
+    }
+
+    // GraphBuilder
+
+    static_assert(sizeof(GraphBuilder) == sizeof(WNNGraphBuilder), "sizeof mismatch for GraphBuilder");
+    static_assert(alignof(GraphBuilder) == alignof(WNNGraphBuilder), "alignof mismatch for GraphBuilder");
+
+    Operand GraphBuilder::Abs(Operand const& input) const {
+        auto result = wnnGraphBuilderAbs(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Add(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderAdd(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::AveragePool2d(Operand const& input, Pool2dOptions const * options) const {
+        auto result = wnnGraphBuilderAveragePool2d(GetHandle(), input.GetHandle(), reinterpret_cast<WNNPool2dOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::BatchNorm(Operand const& input, Operand const& mean, Operand const& variance, BatchNormOptions const * options) const {
+        auto result = wnnGraphBuilderBatchNorm(GetHandle(), input.GetHandle(), mean.GetHandle(), variance.GetHandle(), reinterpret_cast<WNNBatchNormOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Graph GraphBuilder::Build(NamedOperands const& namedOperands) const {
+        auto result = wnnGraphBuilderBuild(GetHandle(), namedOperands.GetHandle());
+        return Graph::Acquire(result);
+    }
+    Operand GraphBuilder::Ceil(Operand const& input) const {
+        auto result = wnnGraphBuilderCeil(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Clamp(Operand const& input, ClampOptions const * options) const {
+        auto result = wnnGraphBuilderClamp(GetHandle(), input.GetHandle(), reinterpret_cast<WNNClampOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    FusionOperator GraphBuilder::ClampOperator(ClampOptions const * options) const {
+        auto result = wnnGraphBuilderClampOperator(GetHandle(), reinterpret_cast<WNNClampOptions const * >(options));
+        return FusionOperator::Acquire(result);
+    }
+    Operand GraphBuilder::Concat(uint32_t inputsCount, Operand const * inputs, uint32_t axis) const {
+        auto result = wnnGraphBuilderConcat(GetHandle(), inputsCount, reinterpret_cast<WNNOperand const * >(inputs), axis);
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Constant(OperandDescriptor const * desc, ArrayBufferView const * value) const {
+        auto result = wnnGraphBuilderConstant(GetHandle(), reinterpret_cast<WNNOperandDescriptor const * >(desc), reinterpret_cast<WNNArrayBufferView const * >(value));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ConstantWithGpuBuffer(OperandDescriptor const * desc, GpuBufferView const * value) const {
+        auto result = wnnGraphBuilderConstantWithGpuBuffer(GetHandle(), reinterpret_cast<WNNOperandDescriptor const * >(desc), reinterpret_cast<WNNGpuBufferView const * >(value));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ConvTranspose2d(Operand const& input, Operand const& filter, ConvTranspose2dOptions const * options) const {
+        auto result = wnnGraphBuilderConvTranspose2d(GetHandle(), input.GetHandle(), filter.GetHandle(), reinterpret_cast<WNNConvTranspose2dOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Conv2d(Operand const& input, Operand const& filter, Conv2dOptions const * options) const {
+        auto result = wnnGraphBuilderConv2d(GetHandle(), input.GetHandle(), filter.GetHandle(), reinterpret_cast<WNNConv2dOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Cos(Operand const& input) const {
+        auto result = wnnGraphBuilderCos(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Div(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderDiv(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Exp(Operand const& input) const {
+        auto result = wnnGraphBuilderExp(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Floor(Operand const& input) const {
+        auto result = wnnGraphBuilderFloor(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Gemm(Operand const& a, Operand const& b, GemmOptions const * options) const {
+        auto result = wnnGraphBuilderGemm(GetHandle(), a.GetHandle(), b.GetHandle(), reinterpret_cast<WNNGemmOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    OperandArray GraphBuilder::Gru(Operand const& input, Operand const& weight, Operand const& recurrentWeight, int32_t steps, int32_t hiddenSize, GruOptions const * options) const {
+        auto result = wnnGraphBuilderGru(GetHandle(), input.GetHandle(), weight.GetHandle(), recurrentWeight.GetHandle(), steps, hiddenSize, reinterpret_cast<WNNGruOptions const * >(options));
+        return OperandArray::Acquire(result);
+    }
+    Operand GraphBuilder::HardSwish(Operand const& input) const {
+        auto result = wnnGraphBuilderHardSwish(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    FusionOperator GraphBuilder::HardSwishOperator() const {
+        auto result = wnnGraphBuilderHardSwishOperator(GetHandle());
+        return FusionOperator::Acquire(result);
+    }
+    Operand GraphBuilder::Input(char const * name, OperandDescriptor const * desc) const {
+        auto result = wnnGraphBuilderInput(GetHandle(), reinterpret_cast<char const * >(name), reinterpret_cast<WNNOperandDescriptor const * >(desc));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::InstanceNorm(Operand const& input, InstanceNormOptions const * options) const {
+        auto result = wnnGraphBuilderInstanceNorm(GetHandle(), input.GetHandle(), reinterpret_cast<WNNInstanceNormOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::L2Pool2d(Operand const& input, Pool2dOptions const * options) const {
+        auto result = wnnGraphBuilderL2Pool2d(GetHandle(), input.GetHandle(), reinterpret_cast<WNNPool2dOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::LeakyRelu(Operand const& input, LeakyReluOptions const * options) const {
+        auto result = wnnGraphBuilderLeakyRelu(GetHandle(), input.GetHandle(), reinterpret_cast<WNNLeakyReluOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    FusionOperator GraphBuilder::LeakyReluOperator(LeakyReluOptions const * options) const {
+        auto result = wnnGraphBuilderLeakyReluOperator(GetHandle(), reinterpret_cast<WNNLeakyReluOptions const * >(options));
+        return FusionOperator::Acquire(result);
+    }
+    Operand GraphBuilder::Log(Operand const& input) const {
+        auto result = wnnGraphBuilderLog(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Matmul(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderMatmul(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Max(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderMax(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::MaxPool2d(Operand const& input, Pool2dOptions const * options) const {
+        auto result = wnnGraphBuilderMaxPool2d(GetHandle(), input.GetHandle(), reinterpret_cast<WNNPool2dOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Min(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderMin(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Mul(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderMul(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Neg(Operand const& input) const {
+        auto result = wnnGraphBuilderNeg(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Pad(Operand const& input, Operand const& padding, PadOptions const * options) const {
+        auto result = wnnGraphBuilderPad(GetHandle(), input.GetHandle(), padding.GetHandle(), reinterpret_cast<WNNPadOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Pow(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderPow(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceArgMax(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceArgMax(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceArgMin(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceArgMin(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceL1(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceL1(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceL2(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceL2(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceMax(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceMax(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceMean(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceMean(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceMin(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceMin(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceProduct(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceProduct(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::ReduceSum(Operand const& input, ReduceOptions const * options) const {
+        auto result = wnnGraphBuilderReduceSum(GetHandle(), input.GetHandle(), reinterpret_cast<WNNReduceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Relu(Operand const& input) const {
+        auto result = wnnGraphBuilderRelu(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    FusionOperator GraphBuilder::ReluOperator() const {
+        auto result = wnnGraphBuilderReluOperator(GetHandle());
+        return FusionOperator::Acquire(result);
+    }
+    Operand GraphBuilder::Resample2d(Operand const& input, Resample2dOptions const * options) const {
+        auto result = wnnGraphBuilderResample2d(GetHandle(), input.GetHandle(), reinterpret_cast<WNNResample2dOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Reshape(Operand const& input, int32_t const * newShape, uint32_t newShapeCount) const {
+        auto result = wnnGraphBuilderReshape(GetHandle(), input.GetHandle(), reinterpret_cast<int32_t const * >(newShape), newShapeCount);
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Sigmoid(Operand const& input) const {
+        auto result = wnnGraphBuilderSigmoid(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    FusionOperator GraphBuilder::SigmoidOperator() const {
+        auto result = wnnGraphBuilderSigmoidOperator(GetHandle());
+        return FusionOperator::Acquire(result);
+    }
+    Operand GraphBuilder::Sin(Operand const& input) const {
+        auto result = wnnGraphBuilderSin(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Slice(Operand const& input, int32_t const * starts, uint32_t startsCount, int32_t const * sizes, uint32_t sizesCount, SliceOptions const * options) const {
+        auto result = wnnGraphBuilderSlice(GetHandle(), input.GetHandle(), reinterpret_cast<int32_t const * >(starts), startsCount, reinterpret_cast<int32_t const * >(sizes), sizesCount, reinterpret_cast<WNNSliceOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Softmax(Operand const& input) const {
+        auto result = wnnGraphBuilderSoftmax(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    OperandArray GraphBuilder::Split(Operand const& input, uint32_t const * splits, uint32_t splitsCount, SplitOptions const * options) const {
+        auto result = wnnGraphBuilderSplit(GetHandle(), input.GetHandle(), reinterpret_cast<uint32_t const * >(splits), splitsCount, reinterpret_cast<WNNSplitOptions const * >(options));
+        return OperandArray::Acquire(result);
+    }
+    Operand GraphBuilder::Squeeze(Operand const& input, SqueezeOptions const * options) const {
+        auto result = wnnGraphBuilderSqueeze(GetHandle(), input.GetHandle(), reinterpret_cast<WNNSqueezeOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Sub(Operand const& a, Operand const& b) const {
+        auto result = wnnGraphBuilderSub(GetHandle(), a.GetHandle(), b.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Tan(Operand const& input) const {
+        auto result = wnnGraphBuilderTan(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    Operand GraphBuilder::Tanh(Operand const& input) const {
+        auto result = wnnGraphBuilderTanh(GetHandle(), input.GetHandle());
+        return Operand::Acquire(result);
+    }
+    FusionOperator GraphBuilder::TanhOperator() const {
+        auto result = wnnGraphBuilderTanhOperator(GetHandle());
+        return FusionOperator::Acquire(result);
+    }
+    Operand GraphBuilder::Transpose(Operand const& input, TransposeOptions const * options) const {
+        auto result = wnnGraphBuilderTranspose(GetHandle(), input.GetHandle(), reinterpret_cast<WNNTransposeOptions const * >(options));
+        return Operand::Acquire(result);
+    }
+    void GraphBuilder::WebnnReference(WNNGraphBuilder handle) {
+        if (handle != nullptr) {
+            wnnGraphBuilderReference(handle);
+        }
+    }
+    void GraphBuilder::WebnnRelease(WNNGraphBuilder handle) {
+        if (handle != nullptr) {
+            wnnGraphBuilderRelease(handle);
+        }
+    }
+
+    // Instance
+
+    static_assert(sizeof(Instance) == sizeof(WNNInstance), "sizeof mismatch for Instance");
+    static_assert(alignof(Instance) == alignof(WNNInstance), "alignof mismatch for Instance");
+
+    Context Instance::CreateContext(ContextOptions const * options) const {
+        auto result = wnnInstanceCreateContext(GetHandle(), reinterpret_cast<WNNContextOptions const * >(options));
+        return Context::Acquire(result);
+    }
+    Context Instance::CreateContextWithGpuDevice(GpuDevice const * gpuDevice) const {
+        auto result = wnnInstanceCreateContextWithGpuDevice(GetHandle(), reinterpret_cast<WNNGpuDevice const * >(gpuDevice));
+        return Context::Acquire(result);
+    }
+    GraphBuilder Instance::CreateGraphBuilder(Context const& context) const {
+        auto result = wnnInstanceCreateGraphBuilder(GetHandle(), context.GetHandle());
+        return GraphBuilder::Acquire(result);
+    }
+    NamedInputs Instance::CreateNamedInputs() const {
+        auto result = wnnInstanceCreateNamedInputs(GetHandle());
+        return NamedInputs::Acquire(result);
+    }
+    NamedOperands Instance::CreateNamedOperands() const {
+        auto result = wnnInstanceCreateNamedOperands(GetHandle());
+        return NamedOperands::Acquire(result);
+    }
+    NamedOutputs Instance::CreateNamedOutputs() const {
+        auto result = wnnInstanceCreateNamedOutputs(GetHandle());
+        return NamedOutputs::Acquire(result);
+    }
+    OperatorArray Instance::CreateOperatorArray() const {
+        auto result = wnnInstanceCreateOperatorArray(GetHandle());
+        return OperatorArray::Acquire(result);
+    }
+    void Instance::WebnnReference(WNNInstance handle) {
+        if (handle != nullptr) {
+            wnnInstanceReference(handle);
+        }
+    }
+    void Instance::WebnnRelease(WNNInstance handle) {
+        if (handle != nullptr) {
+            wnnInstanceRelease(handle);
+        }
+    }
+
+    // NamedInputs
+
+    static_assert(sizeof(NamedInputs) == sizeof(WNNNamedInputs), "sizeof mismatch for NamedInputs");
+    static_assert(alignof(NamedInputs) == alignof(WNNNamedInputs), "alignof mismatch for NamedInputs");
+
+    void NamedInputs::Set(char const * name, Input const * input) const {
+        wnnNamedInputsSet(GetHandle(), reinterpret_cast<char const * >(name), reinterpret_cast<WNNInput const * >(input));
+    }
+    void NamedInputs::WebnnReference(WNNNamedInputs handle) {
+        if (handle != nullptr) {
+            wnnNamedInputsReference(handle);
+        }
+    }
+    void NamedInputs::WebnnRelease(WNNNamedInputs handle) {
+        if (handle != nullptr) {
+            wnnNamedInputsRelease(handle);
+        }
+    }
+
+    // NamedOperands
+
+    static_assert(sizeof(NamedOperands) == sizeof(WNNNamedOperands), "sizeof mismatch for NamedOperands");
+    static_assert(alignof(NamedOperands) == alignof(WNNNamedOperands), "alignof mismatch for NamedOperands");
+
+    void NamedOperands::Set(char const * name, Operand const& operand) const {
+        wnnNamedOperandsSet(GetHandle(), reinterpret_cast<char const * >(name), operand.GetHandle());
+    }
+    void NamedOperands::WebnnReference(WNNNamedOperands handle) {
+        if (handle != nullptr) {
+            wnnNamedOperandsReference(handle);
+        }
+    }
+    void NamedOperands::WebnnRelease(WNNNamedOperands handle) {
+        if (handle != nullptr) {
+            wnnNamedOperandsRelease(handle);
+        }
+    }
+
+    // NamedOutputs
+
+    static_assert(sizeof(NamedOutputs) == sizeof(WNNNamedOutputs), "sizeof mismatch for NamedOutputs");
+    static_assert(alignof(NamedOutputs) == alignof(WNNNamedOutputs), "alignof mismatch for NamedOutputs");
+
+    void NamedOutputs::Get(char const * name, ArrayBufferView * resource) const {
+        wnnNamedOutputsGet(GetHandle(), reinterpret_cast<char const * >(name), reinterpret_cast<WNNArrayBufferView * >(resource));
+    }
+    void NamedOutputs::Set(char const * name, Resource const * resource) const {
+        wnnNamedOutputsSet(GetHandle(), reinterpret_cast<char const * >(name), reinterpret_cast<WNNResource const * >(resource));
+    }
+    void NamedOutputs::WebnnReference(WNNNamedOutputs handle) {
+        if (handle != nullptr) {
+            wnnNamedOutputsReference(handle);
+        }
+    }
+    void NamedOutputs::WebnnRelease(WNNNamedOutputs handle) {
+        if (handle != nullptr) {
+            wnnNamedOutputsRelease(handle);
+        }
+    }
+
+    // Operand
+
+    static_assert(sizeof(Operand) == sizeof(WNNOperand), "sizeof mismatch for Operand");
+    static_assert(alignof(Operand) == alignof(WNNOperand), "alignof mismatch for Operand");
+
+    void Operand::WebnnReference(WNNOperand handle) {
+        if (handle != nullptr) {
+            wnnOperandReference(handle);
+        }
+    }
+    void Operand::WebnnRelease(WNNOperand handle) {
+        if (handle != nullptr) {
+            wnnOperandRelease(handle);
+        }
+    }
+
+    // OperandArray
+
+    static_assert(sizeof(OperandArray) == sizeof(WNNOperandArray), "sizeof mismatch for OperandArray");
+    static_assert(alignof(OperandArray) == alignof(WNNOperandArray), "alignof mismatch for OperandArray");
+
+    Operand OperandArray::Get(size_t index) const {
+        auto result = wnnOperandArrayGet(GetHandle(), index);
+        return Operand::Acquire(result);
+    }
+    size_t OperandArray::Size() const {
+        auto result = wnnOperandArraySize(GetHandle());
+        return result;
+    }
+    void OperandArray::WebnnReference(WNNOperandArray handle) {
+        if (handle != nullptr) {
+            wnnOperandArrayReference(handle);
+        }
+    }
+    void OperandArray::WebnnRelease(WNNOperandArray handle) {
+        if (handle != nullptr) {
+            wnnOperandArrayRelease(handle);
+        }
+    }
+
+    // OperatorArray
+
+    static_assert(sizeof(OperatorArray) == sizeof(WNNOperatorArray), "sizeof mismatch for OperatorArray");
+    static_assert(alignof(OperatorArray) == alignof(WNNOperatorArray), "alignof mismatch for OperatorArray");
+
+    FusionOperator OperatorArray::Get(size_t index) const {
+        auto result = wnnOperatorArrayGet(GetHandle(), index);
+        return FusionOperator::Acquire(result);
+    }
+    void OperatorArray::Set(FusionOperator const& wnnOperator) const {
+        wnnOperatorArraySet(GetHandle(), wnnOperator.GetHandle());
+    }
+    size_t OperatorArray::Size() const {
+        auto result = wnnOperatorArraySize(GetHandle());
+        return result;
+    }
+    void OperatorArray::WebnnReference(WNNOperatorArray handle) {
+        if (handle != nullptr) {
+            wnnOperatorArrayReference(handle);
+        }
+    }
+    void OperatorArray::WebnnRelease(WNNOperatorArray handle) {
+        if (handle != nullptr) {
+            wnnOperatorArrayRelease(handle);
+        }
+    }
+
+    GraphBuilder CreateGraphBuilder(Context context) {
+        return GraphBuilder::Acquire(webnnCreateGraphBuilder(context.GetHandle()));
+    }
+
+    NamedInputs CreateNamedInputs() {
+        return NamedInputs::Acquire(webnnCreateNamedInputs());
+    }
+
+    NamedOperands CreateNamedOperands() {
+        return NamedOperands::Acquire(webnnCreateNamedOperands());
+    }
+
+    NamedOutputs CreateNamedOutputs() {
+        return NamedOutputs::Acquire(webnnCreateNamedOutputs());
+    }
+
+    OperatorArray CreateOperatorArray() {
+        return OperatorArray::Acquire(webnnCreateOperatorArray());
+    }
+
+}
diff --git a/tools/system_libs.py b/tools/system_libs.py
index aae29555d..8df8117ff 100644
--- a/tools/system_libs.py
+++ b/tools/system_libs.py
@@ -1350,6 +1350,12 @@ class libwebgpu_cpp(MTLibrary):
   src_dir = 'system/lib/webgpu'
   src_files = ['webgpu_cpp.cpp']
 
+class libwebnn_cpp(MTLibrary):
+  name = 'libwebnn_cpp'
+
+  cflags = ['-std=c++11']
+  src_dir = 'system/lib/webnn'
+  src_files = ['webnn_cpp.cpp']
 
 class libembind(Library):
   name = 'libembind'
@@ -1787,6 +1793,9 @@ def get_libs_to_link(args, forced, only_forced):
   if settings.USE_WEBGPU:
     add_library('libwebgpu_cpp')
 
+  if settings.USE_WEBNN:
+    add_library('libwebnn_cpp')
+
   return libs_to_link
 
 
